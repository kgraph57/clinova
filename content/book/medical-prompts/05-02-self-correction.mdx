---
title: "自己修正・検証プロンプト"
description: "AIの回答を自己検証させ、誤りを修正させるためのプロンプトテクニック集。ハルシネーション対策を含む。"
slug: "05-02-self-correction"
order: 22
partId: "part05"
partTitle: "高度なテクニック"
partOrder: 5
estimatedMinutes: 20
free: false
status: "published"
tags: ["自己修正", "検証", "ハルシネーション", "品質保証"]
publishedAt: "2026-03-01"
updatedAt: "2026-03-01"
---

## AIの自己修正の重要性

LLMは時に自信を持って誤った情報を出力します（ハルシネーション）。医療領域では、この誤りが重大な結果を招く可能性があります。「AIの回答をAI自身に検証させる」自己修正テクニックは、出力の信頼性を高めるための重要な手法です。

## 基本テクニック: 回答後の自己検証

<PromptTemplate title="回答後の自己検証プロンプト">
[臨床質問に対する回答を得た後に追加する]

今の回答について、以下の観点から自己検証を行ってください。

【検証チェックリスト】
1. 事実の正確性
   - 述べた薬剤名・用量は正しいか
   - 引用したガイドラインは実在し、内容は正確か
   - 数値データ（発生率、感度・特異度等）は正確か

2. 論理の一貫性
   - 推論に矛盾はないか
   - 結論は前提から論理的に導かれているか

3. 網羅性
   - 重要な鑑別や注意点を見落としていないか
   - 考慮すべき禁忌や相互作用を漏らしていないか

4. 確信度の自己評価
   - 各推奨について、確信度を高/中/低で再評価
   - 確信度が低い項目は「要確認」と明示

【出力形式】
■ 修正が必要な箇所
| 箇所 | 元の記述 | 修正内容 | 修正理由 |
|------|---------|---------|---------|

■ 確認が推奨される箇所
[外部データベースでの確認が推奨される事項]

■ 修正後の回答（変更箇所を太字で）
</PromptTemplate>

<ComparisonCard beforeLabel="検証なしの使用" afterLabel="自己検証付きの使用">
<ComparisonBefore>

AIの回答をそのまま受け取る。
「AIがそう言っているから正しいだろう」
→ ハルシネーションのリスクを見逃す

</ComparisonBefore>
<ComparisonAfter>

Step 1: 臨床質問を投げる
Step 2: 回答を受け取る
Step 3: 「この回答を自己検証してください」と追加
Step 4: 自己検証で修正点・不確実点が明示される
Step 5: 重要事項は外部データベースで確認
→ 誤りの早期発見と信頼性の向上

</ComparisonAfter>
</ComparisonCard>

## Devil's Advocate（悪魔の代弁者）テクニック

<PromptTemplate title="Devil's Advocate プロンプト">
あなたの先ほどの回答に対して、今度は「悪魔の代弁者」の立場から批判的に検討してください。

【批判の観点】
1. 反対の立場からの反論
   - この推奨に対する最も強い反対意見は何か
   - 異なるガイドラインや学派の見解はないか

2. 最悪のシナリオ
   - この推奨に従った場合に起こりうる最悪の結果は何か
   - その確率はどの程度か

3. 代替案の再検討
   - 先ほど挙げなかった代替案はないか
   - 却下した選択肢を再評価する理由はないか

4. エビデンスの限界
   - 参照したエビデンスの質は十分か
   - 日本人データの不足はないか
   - 対象患者と研究対象集団の乖離はないか

【出力形式】
■ 最も重要な反論点: [1つ]
■ 考慮すべき代替案: [1-2個]
■ 元の推奨の堅牢性: [変更不要/一部修正/再検討必要]
■ 最終的な推奨（反論を踏まえた修正版）
</PromptTemplate>

## 信頼度スコアリング

<PromptTemplate title="信頼度スコアリングプロンプト">
以下の臨床質問に回答した後、各推奨事項に信頼度スコアを付与してください。

【臨床質問】
[質問内容]

【回答後に追加する指示】
各推奨事項について、以下のスケールで信頼度を自己評価してください：

★★★★★ (5/5): 確立されたエビデンスとガイドラインに基づく
★★★★☆ (4/5): 強いエビデンスがあるが、一部条件付き
★★★☆☆ (3/5): エビデンスはあるが限定的、専門家の意見が分かれる
★★☆☆☆ (2/5): エビデンスが乏しい、臨床経験に基づく推測
★☆☆☆☆ (1/5): ほぼ推測、確認が強く推奨される

【出力形式】
| 推奨事項 | 信頼度 | 根拠 | 確認方法 |
|---------|--------|------|---------|
| [推奨1] | ★★★★☆ | [根拠] | [確認先] |
| [推奨2] | ★★☆☆☆ | [根拠] | [確認先] |

信頼度3以下の項目は、必ず外部情報源で確認してから採用してください。
</PromptTemplate>

## ハルシネーション検出プロンプト

<PromptTemplate title="ハルシネーション検出特化プロンプト">
先ほどの回答について、ハルシネーション（事実に反する情報の生成）がないか検証してください。

【特に検証すべき項目】
1. 固有名詞の正確性
   - 挙げた薬剤名は実在するか
   - 言及したガイドラインは正確な名称か
   - 引用した研究/論文は実在する可能性が高いか

2. 数値データの妥当性
   - 挙げた発生率・有病率は妥当な範囲か
   - 薬剤の用量は添付文書と整合するか
   - 感度・特異度のデータは既知のデータと矛盾しないか

3. 因果関係の正確性
   - 因果関係と相関関係を混同していないか
   - 述べた機序は確立されたものか

4. 時系列の正確性
   - ガイドラインの年度は正確か
   - 薬剤の承認状況は最新か

【出力形式】
■ 高確信（事実として正しい可能性が高い）
[リスト]

■ 中確信（おそらく正しいが確認推奨）
[リスト]

■ 低確信（ハルシネーションの可能性あり、必ず確認）
[リスト]

■ 外部確認が推奨されるリソース
- 薬剤情報: [添付文書DB/KEGG DRUG]
- ガイドライン: [学会サイト]
- 文献: [PubMed]
</PromptTemplate>

## 二重チェック型プロンプト

<PromptTemplate title="二重チェック（ダブルチェック）プロンプト">
以下の臨床質問について、2つの異なるアプローチで回答し、結果を比較してください。

【臨床質問】
[質問内容]

【アプローチ1: ガイドライン準拠】
関連するガイドラインに基づいて回答してください。

【アプローチ2: 臨床推論ベース】
ガイドラインに依存せず、基本的な病態生理と臨床推論に基づいて回答してください。

【比較】
2つのアプローチの結果を比較し：
1. 一致する点: [両方が同じ結論に達した部分]
2. 不一致な点: [異なる結論になった部分]
3. 不一致の分析: [なぜ異なるのか、どちらが適切か]
4. 最終推奨: [2つのアプローチを統合した推奨]

不一致がある場合、その部分は特に慎重に検討すべきポイントです。
</PromptTemplate>

<Warning>
AIの自己修正には限界があります。AIが「自分の回答に誤りはない」と判断した場合でも、実際には誤りが含まれている可能性があります。自己検証プロンプトは追加の安全層として活用し、最終的な検証は人間（医療者）が行ってください。
</Warning>

<Callout>
自己修正テクニックのベストプラクティス：
- **毎回使う必要はない**: 高リスクな判断や不確実性が高い場面で使用
- **外部検証と組み合わせる**: AIの自己検証+外部データベースの確認
- **信頼度スコアを活用**: 低スコアの項目を優先的に外部確認
- **Devil's Advocateは重要判断に**: 治療方針の最終決定前に使用
</Callout>

<KeyTakeaway>
自己修正プロンプトは、AIの回答の信頼性を高めるための重要な安全策です。「回答後の自己検証」「Devil's Advocate」「信頼度スコアリング」「ハルシネーション検出」「二重チェック」の5つのテクニックを場面に応じて使い分けてください。ただし、AIの自己検証は万能ではありません。最終的な確認は常に人間が行う必要があります。
</KeyTakeaway>
