---
title: "AI利用ガバナンスフレームワーク"
description: "医療機関におけるAI利用のガバナンス体制、ポリシー、リスク管理、倫理審査の包括的なフレームワーク設計。"
slug: "06-02-governance"
order: 19
partId: "part06"
partTitle: "スケールアップ"
partOrder: 2
estimatedMinutes: 20
free: false
status: "published"
tags: ["ガバナンス", "AI倫理", "リスク管理", "コンプライアンス", "ポリシー"]
publishedAt: "2026-03-01"
updatedAt: "2026-03-01"
---

# AI利用ガバナンスフレームワーク

AI活用が組織全体に広がると、「誰が、何の権限で、どのルールに従ってAIを使うか」を明確にするガバナンスフレームワークが不可欠になります。本章では、医療機関特有の要件を考慮したAIガバナンスの設計手法を解説します。

## なぜAIガバナンスが必要か

<StatHighlight value="67%" label="AI利用に関する正式なガバナンスポリシーを持たない医療機関の割合（日本国内）" source="日本医療情報学会調査, 2025" />

パイロットの段階では、少数のスタッフが限定的にAIを使用するため、暗黙のルールで運用できます。しかし、全院展開が進むと以下の問題が顕在化します。

<Callout title="ガバナンス不在のリスク">
1. **AIの不適切な使用** — 想定外のユースケースでの利用、AIの過信による判断ミス
2. **責任の不明確さ** — AIが関与した医療事故の責任分界が不明
3. **データの不適切な利用** — 患者データのAI学習への利用範囲が不明確
4. **品質の担保困難** — AIモデルの性能劣化（ドリフト）を検知できない
5. **規制違反** — 薬事法、個人情報保護法、各種ガイドラインへの抵触
</Callout>

## AIガバナンスの3層構造

<StepFlow>
<StepFlowStep number={1} title="第1層：ガバナンス体制（Who）">
AIの導入・運用・評価に責任を持つ組織体制。意思決定プロセス、報告ライン、委員会構成。
</StepFlowStep>
<StepFlowStep number={2} title="第2層：ポリシーと基準（What）">
AI利用のルール、基準、手順を明文化した文書体系。利用ポリシー、安全基準、倫理ガイドライン。
</StepFlowStep>
<StepFlowStep number={3} title="第3層：運用プロセス（How）">
ガバナンスを日常的に機能させるプロセス。監査、モニタリング、インシデント対応、改善。
</StepFlowStep>
</StepFlow>

## 第1層：ガバナンス体制の設計

### AI利用委員会の設置

<PromptTemplate title="AI利用委員会 設置要綱テンプレート">
**1. 名称：** [例：AI利用推進・倫理委員会]

**2. 目的：**
- 医療AI利用に関するポリシーの策定と見直し
- 新規AIツール導入の審査と承認
- AI利用に関するインシデントの調査と対策
- AI倫理に関する方針の策定

**3. 構成メンバー：**
| 役割 | 職位 | 担当領域 |
|------|------|---------|
| 委員長 | 副病院長（医療安全担当） | 全体統括 |
| 副委員長 | CIO/医療情報部長 | 技術・情報管理 |
| 委員 | 臨床部門代表（2-3名） | 臨床的適切性 |
| 委員 | 看護部代表 | 看護業務への影響 |
| 委員 | 薬剤部代表 | 薬事規制 |
| 委員 | 医療安全管理者 | 安全性評価 |
| 委員 | 法務/コンプライアンス | 法的リスク |
| 委員 | 患者代表（外部） | 患者視点 |
| 事務局 | PM/AI推進担当 | 運営事務 |

**4. 開催頻度：** 定例月1回 + 臨時開催（インシデント発生時）

**5. 権限：**
- 新規AIツール導入の最終承認権限
- AI利用ポリシーの制定・改廃
- AI関連インシデント調査の指示権限
- AI利用の一時停止命令権限

**6. 報告ライン：** 病院長/理事会への四半期報告
</PromptTemplate>

### AI導入審査プロセス

新しいAIツールを導入する際の審査プロセスを標準化します。

<StepFlow>
<StepFlowStep number={1} title="申請（申請者）">
AI導入申請書を提出。ユースケース、期待効果、リスク評価、データ利用計画を記載。
</StepFlowStep>
<StepFlowStep number={2} title="技術審査（IT部門）">
技術的な実現可能性、セキュリティ要件、既存システムとの互換性を評価。2週間。
</StepFlowStep>
<StepFlowStep number={3} title="臨床審査（臨床部門代表）">
臨床的な有用性、安全性、ワークフローへの影響を評価。2週間。
</StepFlowStep>
<StepFlowStep number={4} title="倫理審査（AI利用委員会）">
倫理的な配慮、バイアスリスク、患者への影響を評価。必要に応じてIRB（倫理審査委員会）に付議。1ヶ月。
</StepFlowStep>
<StepFlowStep number={5} title="承認/条件付き承認/却下">
AI利用委員会が最終判断。条件付き承認の場合は条件の明示と履行確認プロセスを設定。
</StepFlowStep>
</StepFlow>

## 第2層：ポリシーと基準

### AI利用ポリシーの構成

<PromptTemplate title="医療AI利用ポリシー テンプレート（主要セクション）">
**1. 目的と適用範囲**
- ポリシーの目的
- 適用対象（AIツール、対象者、対象業務）
- 用語の定義

**2. AI利用の基本原則**
- 患者中心の原則：AIの利用は常に患者利益を最優先とする
- 透明性の原則：AIの利用を患者に適切に説明する
- 公平性の原則：AIによる差別やバイアスを防止する
- 安全性の原則：AIの誤りによる患者への害を最小化する
- 説明責任の原則：AIの判断に対する責任の所在を明確にする

**3. AIの利用範囲と制限**
- 許可される利用範囲（業務支援、意思決定支援）
- 禁止される利用（AIのみによる最終診断、AIの判断に基づく治療の自動開始）
- 段階的な利用レベルの定義

**4. 責任分界**
- AIの出力に基づく臨床判断の最終責任は担当医師にある
- AI出力と医師の判断が異なる場合の対処手順
- AI関連インシデント発生時の責任体系

**5. データ管理**
- AIに入力するデータの範囲
- AIの学習に利用するデータの同意取得プロセス
- データの匿名化・仮名加工の基準
- データの保存期間と廃棄手順

**6. 品質管理**
- AI性能の定期モニタリング（頻度、方法）
- 性能劣化の検知基準とアクション
- AIモデル更新時のバリデーションプロセス

**7. インシデント対応**
- AI関連インシデントの定義と分類
- 報告手順と報告先
- 調査プロセスと再発防止策
- 緊急時のAI利用停止判断基準

**8. 教育・トレーニング**
- AI利用者に必要な研修と認定
- 定期的なスキル更新の要件

**9. ポリシーの見直し**
- 年1回の定期見直し
- 見直しトリガー（インシデント、規制変更、技術更新）
</PromptTemplate>

### AI利用レベルの定義

AIの利用を段階的に定義し、レベルに応じた管理要件を設定します。

| レベル | 定義 | 例 | 管理要件 |
|--------|------|-----|---------|
| Level 1 | 情報提示 | 関連文献の表示、データの要約 | 標準的 |
| Level 2 | 判断支援 | リスクスコアの提示、異常の指摘 | AI利用ポリシー遵守 |
| Level 3 | 推奨提示 | 治療オプションの推奨、投薬量の提案 | 医師の確認必須 |
| Level 4 | 自動化（限定的） | アラートの自動送信、スケジュール最適化 | 委員会承認 + 定期監査 |
| Level 5 | 自律的判断 | 現在は原則禁止 | 個別承認 + 倫理審査 |

## 第3層：運用プロセス

### AI性能モニタリング

<Callout title="AIモデルドリフトの監視">
AIモデルは時間の経過とともに性能が劣化する「ドリフト」が発生する可能性があります。原因は、患者集団の変化、データ品質の変動、業務プロセスの変更など。

**監視すべき指標：**
- 予測精度（感度、特異度）の推移
- AIの確信度の分布変化
- AI出力と最終判断の不一致率の変化
- ユーザーからの異常報告数

**アクション基準：**
- 黄信号：性能指標がベースラインから10%低下 → モニタリング強化
- 赤信号：性能指標がベースラインから20%低下 → 利用制限、ベンダーへの報告、改善要求
- 緊急停止：患者安全に関わるインシデント → 即時利用停止、調査開始
</Callout>

### インシデント対応フレームワーク

<StepFlow>
<StepFlowStep number={1} title="検知と報告（0-1時間）">
AI関連のインシデントまたはニアミスを検知した場合、既存のインシデント報告システムに「AI関連」フラグを付けて報告。重大インシデントの場合は医療安全管理者に即時報告。
</StepFlowStep>
<StepFlowStep number={2} title="初期対応（1-4時間）">
患者安全の確保を最優先。必要に応じてAI利用の一時停止。インシデントの概要を把握し、関係者に通知。
</StepFlowStep>
<StepFlowStep number={3} title="調査と分析（1-7日）">
RCA（根本原因分析）を実施。AIの出力内容、利用者の判断プロセス、システムログを確認。AIの不具合か、利用方法の問題か、両方の複合かを判定。
</StepFlowStep>
<StepFlowStep number={4} title="是正措置（1-4週間）">
根本原因に基づく是正措置を実施。AIモデルの修正、運用手順の変更、追加トレーニングなど。ベンダーとの協議が必要な場合はエスカレーション。
</StepFlowStep>
<StepFlowStep number={5} title="再発防止と共有（1ヶ月以内）">
再発防止策を策定し、組織全体に共有。AI利用ポリシーの改訂が必要な場合はAI利用委員会に上程。
</StepFlowStep>
</StepFlow>

### コンプライアンスチェックリスト

<PromptTemplate title="AI利用コンプライアンス定期チェックリスト（四半期実施）">
**法規制対応**
- [ ] 個人情報保護法に準拠したデータ管理が行われている
- [ ] 医療情報システムの安全管理に関するガイドライン（3省2ガイドライン）に準拠
- [ ] 薬事規制対象のAIについて、承認範囲内で使用されている
- [ ] 患者への適切な説明と同意取得が行われている

**データ管理**
- [ ] AIに入力するデータの範囲がポリシーに準拠している
- [ ] データの匿名化/仮名加工が適切に行われている
- [ ] ベンダーとのデータ利用契約が最新である
- [ ] データのバックアップと災害復旧計画が有効である

**品質管理**
- [ ] AI性能モニタリングが計画通り実施されている
- [ ] 性能低下の兆候がないか確認されている
- [ ] AIモデルのバージョン管理が適切に行われている
- [ ] ベンダーのSLA（サービスレベル合意）が遵守されている

**運用管理**
- [ ] 全AI利用者が必要な研修を修了している
- [ ] チャンピオンが各部門に配置されている
- [ ] インシデント報告ルートが機能している
- [ ] AI利用ポリシーが全スタッフに周知されている
</PromptTemplate>

## AI倫理フレームワーク

### 医療AI倫理の7原則

<Callout title="WHO「AIの倫理とガバナンス」ガイダンスに基づく7原則">
1. **人間の自律性の保護** — AIは人間の意思決定を支援するが、代替しない
2. **人間の福祉と安全の促進** — AIは患者と医療従事者の利益のために使用する
3. **透明性と説明可能性** — AIの動作原理と判断根拠を説明できること
4. **責任の明確化** — AIに関連する判断の責任者を明確にする
5. **包摂性と公平性** — AIが特定の集団に不利に働かないことを確保する
6. **応答性と持続可能性** — AIの性能を継続的にモニタリングし改善する
7. **プライバシーとデータ保護** — 患者データの適切な管理と保護
</Callout>

### バイアス監査の実施

<Warning>
AIモデルは学習データに含まれるバイアスを反映する可能性があります。特に医療AIでは、人種、性別、年齢、社会経済的地位によるバイアスが患者アウトカムに直接影響するため、定期的なバイアス監査が不可欠です。
</Warning>

| 監査項目 | 確認方法 | 頻度 |
|---------|---------|------|
| 人口統計学的バイアス | AIの予測精度を性別、年齢群、疾患群ごとに比較 | 半年ごと |
| ラベルバイアス | 学習データのラベル付けの一貫性を確認 | モデル更新時 |
| 選択バイアス | 学習データの代表性を確認（自施設の患者集団との乖離） | 年1回 |
| 測定バイアス | データ収集方法による系統的な歪みの確認 | 年1回 |

## ケーススタディ：Partners Healthcare（現Mass General Brigham）のAIガバナンス

Partners Healthcare（現Mass General Brigham）は、米国でいち早くAIガバナンスフレームワークを確立した医療機関です。

**ガバナンス体制：**
- AI Steering Committee（経営レベル、四半期開催）
- AI Review Board（技術・臨床・倫理の審査、月次開催）
- AI Operations Team（日常運用、常設）

**主要ポリシー：**
- 全AIツールの導入前審査の義務化（AI Review Boardによる承認制）
- 臨床使用するAIの年次バリデーション義務
- AIバイアス監査の半年ごとの実施
- AI関連インシデントの72時間以内報告義務
- 患者への「AIの使用」の開示ポリシー

**成果：**
- 3年間で52のAIアプリケーションを審査、35を承認
- AIバイアスの事前検出：6件（導入前に対策完了）
- AI関連のインシデント：ゼロ（重大インシデント）

<KeyTakeaway>
AIガバナンスは「体制（Who）」「ポリシー（What）」「プロセス（How）」の3層で構成する。AI利用委員会を設置し、新規AIの導入審査と既存AIの品質監視を制度化する。AIの利用レベルを段階的に定義し、レベルに応じた管理要件を設定する。倫理フレームワーク（WHO 7原則）を組織に適用し、定期的なバイアス監査を実施する。ガバナンスは「規制」ではなく「安全にAIの価値を最大化するための仕組み」である。
</KeyTakeaway>

## 次章に向けて

ガバナンスフレームワークが整備できたら、次は視野を広げ、複数施設へのAI展開と標準化について考えます。次章では、グループ病院や地域連携におけるAI導入の標準化戦略を解説します。
