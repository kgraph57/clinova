---
title: "クラウドAIサービスへの患者データ入力の法的リスク"
description: "ChatGPTやClaude等のクラウドAIサービスに患者データを入力する際の法的リスクと、適法に活用するための実務指針を解説する。"
slug: "05-02-cloud-ai"
order: 16
partId: "part05"
partTitle: "患者データとプライバシー"
partOrder: 2
estimatedMinutes: 20
free: false
status: "published"
tags: ["クラウドAI", "ChatGPT", "個人情報保護法", "第三者提供", "委託", "要配慮個人情報"]
publishedAt: "2026-03-01"
updatedAt: "2026-03-01"
---

**ChatGPTやClaudeなどのクラウドAIサービスを臨床業務に活用する医療従事者が増えている。しかし、これらのサービスに患者データを入力する行為は、個人情報保護法上の重大なリスクを伴う。「便利だから使う」では済まされない法的問題を整理する。**

---

## 問題の所在

### 日常的に起きていること

医療現場では、以下のようなクラウドAIサービスの利用が日常的に行われている。

- 患者の症状をChatGPTに入力して鑑別診断を相談する
- 退院サマリーをLLMに入力して英訳や要約を作成する
- 検査データをAIサービスに入力して解釈を求める
- 紹介状の文案をAIに作成させる
- 症例検討会の資料をAIに作成させる

これらの行為の多くは、個人情報保護法に違反する可能性がある。

### なぜ問題なのか

患者データをクラウドAIサービスに入力する行為は、法的に以下の3つの問題を含みうる。

1. **個人情報の第三者提供**（個人情報保護法第27条違反）
2. **要配慮個人情報の不適切な取得**（AIサービス提供者側の問題）
3. **安全管理措置の不備**（個人情報保護法第23条違反）

<Warning>
「患者名を削除すればよい」という理解は誤りである。氏名を削除しても、年齢、性別、疾患名、検査値、診療日などの組み合わせにより個人が特定可能な場合、それは依然として個人情報に該当する。個人情報保護法は、他の情報と「容易に照合」できるかどうかで判断する（第2条第1項）。
</Warning>

---

## 法的分析

### 第三者提供の該当性

個人情報保護法第27条第1項は、「個人情報取扱事業者は、あらかじめ本人の同意を得ないで、個人データを第三者に提供してはならない」と規定している。

クラウドAIサービスに患者データを入力する行為が「第三者提供」に該当するかどうかは、サービスの利用形態による。

**第三者提供に該当する場合**：
- AIサービス提供者がデータの学習に利用する場合
- データが提供者のサーバーに保存される場合
- 提供者がデータにアクセス可能な状態にある場合

**第三者提供に該当しない場合（委託に該当）**：
- 個人情報の取扱いの「委託」として整理される場合（第27条第5項第1号）

ただし、「委託」として整理するためには、委託元（医療機関）が委託先（AIサービス提供者）に対する監督義務を果たす必要がある（第25条）。

### 要配慮個人情報の問題

患者の疾患名、検査結果、治療内容などの医療データは、「要配慮個人情報」（第2条第3項）に該当する。要配慮個人情報は、取得に原則として本人の同意が必要であり（第20条第2項）、オプトアウト方式による第三者提供も認められない（第27条第2項ただし書）。

<Callout type="warning" title="要配慮個人情報の厳格性">
通常の個人情報であれば、オプトアウト（事前に通知した上で、拒否しない限り第三者提供可能）の余地がある。しかし、要配慮個人情報は一切のオプトアウトが認められない。医療データをクラウドAIサービスに提供するためには、原則として患者の明示的な同意が必要である。
</Callout>

### 外国にある第三者への提供

多くのクラウドAIサービスのサーバーは、米国やEUに所在する。外国にある第三者に個人データを提供する場合、個人情報保護法第28条の追加的要件を満たす必要がある。

**選択肢**：
1. 本人の同意を得る（提供先国のデータ保護制度に関する情報提供が必要）
2. 提供先が個人情報保護委員会の定める基準に適合する体制を整備している
3. 提供先国が日本と同等の個人情報保護制度を有する（EU、英国等）

---

## サービス別の法的リスク分析

### ChatGPT（OpenAI）

<ComparisonCard
  title="ChatGPT利用形態別リスク"
  left={{
    title: "Web版 / モバイルアプリ",
    items: [
      "デフォルトでデータが学習に使用される",
      "オプトアウト設定でも一定期間保存",
      "患者データの入力は第三者提供に該当",
      "要配慮個人情報の同意取得が必要",
      "リスク：極めて高い"
    ]
  }}
  right={{
    title: "API / Azure OpenAI Service",
    items: [
      "APIデータは学習に使用されない（利用規約）",
      "データ保持期間が限定的",
      "委託契約の整備により委託構成が可能",
      "Azure利用時は日本リージョン選択可",
      "リスク：適切な契約により軽減可能"
    ]
  }}
/>

### Claude（Anthropic）

AnthropicのClaude APIは、入力データを学習に使用しない方針を明示している。API利用の場合、適切な利用契約の下で委託構成を検討できる。Web版（claude.ai）の無料プランでは、会話データが改善目的で利用される可能性があるため、患者データの入力は避けるべきである。

### Google Gemini / Microsoft Copilot

各社のAPI版とコンシューマー版で、データの取り扱いポリシーが異なる。医療機関としては、API版またはエンタープライズ版を選択し、データ処理契約（DPA：Data Processing Agreement）を締結した上で利用することが推奨される。

---

## 適法にクラウドAIを活用するための方策

### 方策1：完全な匿名化

患者データを完全に匿名化した上でクラウドAIに入力する。ただし、前章で述べた通り、医療データの完全な匿名化は極めて困難である。

### 方策2：委託契約の締結

AIサービス提供者との間で、個人情報の取扱いに関する委託契約を締結する。委託として整理する場合、第三者提供の同意は不要だが、以下の要件を満たす必要がある。

- 委託契約書の締結
- 委託先の監督（安全管理措置の確認）
- データの利用目的の範囲の限定
- 再委託の制限

### 方策3：オンプレミスまたはプライベートクラウドでの運用

外部クラウドにデータを送信しない環境で、AIモデルを運用する。

- **オンプレミスLLM**：院内サーバーにオープンソースLLM（Llama等）を構築する
- **プライベートクラウド**：医療機関専用のクラウド環境にAIを構築する
- **VPN/閉域網接続**：クラウドAIサービスに閉域網で接続する

### 方策4：患者の同意取得

患者から、クラウドAIサービスへのデータ提供に関する明示的な同意を取得する。ただし、以下の実務的課題がある。

- 同意の範囲（どのAIサービスに、どの目的で）の特定
- AIサービスの変更時の再同意の必要性
- 同意能力のない患者（小児、認知症等）の対応
- 同意の任意性の確保（拒否しても不利益がないこと）

<StepFlow>
<StepFlowStep number={1} title="利用形態の選択">
Web版コンシューマーサービスではなく、API版またはエンタープライズ版を選択する。学習に利用されない利用規約を確認する。
</StepFlowStep>
<StepFlowStep number={2} title="契約の整備">
AIサービス提供者との間で、委託契約またはDPA（Data Processing Agreement）を締結する。データの利用目的、保持期間、安全管理措置、再委託の制限を明記する。
</StepFlowStep>
<StepFlowStep number={3} title="データの加工">
入力するデータを可能な限り匿名化・仮名化する。直接識別子の削除は最低限必須。
</StepFlowStep>
<StepFlowStep number={4} title="院内ルールの策定">
クラウドAIサービスの利用に関する院内ルールを策定し、職員に周知する。利用可能なサービス、利用可能な範囲、禁止事項を明確にする。
</StepFlowStep>
<StepFlowStep number={5} title="監査とモニタリング">
クラウドAIサービスの利用状況を定期的に監査し、院内ルールの遵守状況を確認する。
</StepFlowStep>
</StepFlow>

---

## ケーススタディ

### ケース1：研修医がChatGPTに患者情報を入力

ある研修医が、担当患者の症状、検査結果、治療経過をChatGPTのWeb版に入力し、鑑別診断の相談を行った。入力データには氏名は含まれていなかったが、年齢、性別、入院日、希少疾患の診断名が含まれていた。

**法的問題**：
- 希少疾患の診断名、年齢、性別、入院日の組み合わせにより、特定の個人を識別できる可能性がある
- Web版ChatGPTのデフォルト設定では、データが学習に使用される可能性がある
- 要配慮個人情報の第三者提供に該当する可能性がある
- 患者の同意は取得されていない

### ケース2：病院がAzure OpenAI Serviceを契約して利用

ある病院が、Microsoft Azure OpenAI Serviceとの間で委託契約を締結し、日本リージョンのサーバーを使用して、退院サマリーの自動生成に利用している。

**法的評価**：
- API利用であり、データは学習に使用されない（利用規約上）
- 委託契約を締結しており、第三者提供の例外（委託）に該当しうる
- 日本リージョンの利用により、外国への第三者提供の問題を回避
- 適切な安全管理措置が講じられている

このケースは、法的リスクが適切に軽減された好事例である。

---

## 各団体のガイドライン

### 日本医師会

日本医師会は、医療現場での生成AI利用に関する注意喚起を行っており、患者データの外部AIサービスへの入力について慎重な対応を求めている。

### 厚生労働省

厚生労働省は「医療情報システムの安全管理に関するガイドライン」（第6.0版、2023年5月）において、クラウドサービスの利用に関する安全管理基準を示している。医療AIサービスのクラウド利用にも適用される。

### 個人情報保護委員会

個人情報保護委員会は、生成AIサービスへの個人情報の入力について注意喚起（2023年6月）を行い、利用規約の確認、学習利用の有無の確認、安全管理措置の実施を求めている。

<PromptTemplate title="クラウドAIサービス利用の法的リスクチェックリスト">
**サービス選択時**
- [ ] API版 / エンタープライズ版を選択した（Web版コンシューマーサービスを避ける）
- [ ] 利用規約でデータの学習利用がないことを確認した
- [ ] データの保存場所（リージョン）を確認した
- [ ] サービス提供者のセキュリティ認証（ISO 27001、SOC 2等）を確認した

**契約の整備**
- [ ] 委託契約またはDPAを締結した
- [ ] データの利用目的の範囲を限定した
- [ ] データの保持期間と削除方法を確認した
- [ ] 再委託の制限を確認した

**運用管理**
- [ ] 入力データの匿名化・仮名化ルールを策定した
- [ ] 院内利用ルールを策定し、職員に周知した
- [ ] 利用状況の監査スケジュールを設定した
- [ ] インシデント発生時の対応手順を整備した

**禁止事項の明確化**
- [ ] Web版コンシューマーサービスへの患者データ入力を禁止した
- [ ] 直接識別子（氏名等）の入力を禁止した
- [ ] 院内ルールに反する利用を検知する仕組みを検討した
</PromptTemplate>

<KeyTakeaway>
- クラウドAIサービスへの患者データ入力は、個人情報保護法上の第三者提供に該当しうる
- 要配慮個人情報（医療データ）はオプトアウトが認められず、原則として本人同意が必要
- 氏名を削除しても、他の情報の組み合わせにより個人が特定可能な場合は個人情報に該当する
- API版 / エンタープライズ版の利用と委託契約の締結により、法的リスクを軽減できる
- Web版コンシューマーサービスへの患者データ入力は、事実上避けるべき
- オンプレミスLLMやプライベートクラウドの活用も有力な選択肢
- 院内ルールの策定と職員への周知・監査が不可欠
</KeyTakeaway>
