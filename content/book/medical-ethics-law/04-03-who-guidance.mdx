---
title: "WHO・UNESCO — グローバルガバナンスの潮流"
description: "WHOの医療AI倫理ガイダンスとUNESCOのAI倫理勧告を中心に、グローバルなAIガバナンスの潮流を解説する。"
slug: "04-03-who-guidance"
order: 14
partId: "part04"
partTitle: "世界の規制動向"
partOrder: 3
estimatedMinutes: 20
free: false
status: "published"
tags: ["WHO", "UNESCO", "グローバルガバナンス", "倫理ガイダンス", "LMIC", "UHC"]
publishedAt: "2026-03-01"
updatedAt: "2026-03-01"
---

**EU AI ActやFDA規制が先進国の法的枠組みであるのに対し、WHOとUNESCOは、低中所得国を含むグローバルな視点からAIガバナンスの原則と指針を示している。国際的な規範形成の潮流を理解することは、医療AI倫理の全体像を把握する上で不可欠である。**

---

## WHOの医療AI倫理ガイダンス

### Ethics and Governance of Artificial Intelligence for Health（2021年）

WHOは2021年6月、「Ethics and Governance of Artificial Intelligence for Health」を公表した。これは、国際機関が発行した初の包括的な医療AI倫理ガイダンスである。

2年間にわたる専門家会合と広範なコンサルテーションを経て策定され、医療AIの設計・開発・導入・監視に関する6つの指導原則を示している。

### WHOの6原則

**原則1：人間の自律性の保護（Protecting Human Autonomy）**

AIシステムの設計と使用において、人間が意思決定の支配権を維持することを求める。医師がAIの推奨を無視する権限を保持し、患者がAI支援の医療に関するインフォームドコンセントを行える環境を確保する。

**原則2：人間の福祉と安全の促進（Promoting Human Well-being and Safety）**

AIが人間の福祉を向上させ、安全性を確保することを求める。特に、AIが意図しない害を引き起こすリスクを最小化するための設計と監視の仕組みが重要である。

**原則3：透明性、説明可能性、理解可能性の確保（Ensuring Transparency, Explainability, and Intelligibility）**

AIの動作原理、学習データ、判断プロセスに関する透明性を求める。利用者（医師・患者）がAIの出力を理解し、評価できる程度の情報提供が必要。

**原則4：責任とアカウンタビリティの確保（Fostering Responsibility and Accountability）**

AIの開発者、提供者、利用者の責任を明確にし、AI由来の害が発生した場合の救済メカニズムを整備することを求める。

**原則5：包摂性と公平性の確保（Ensuring Inclusiveness and Equity）**

AIが健康格差を拡大するのではなく、縮小する方向で設計・導入されることを求める。特に、低中所得国（LMIC）やデジタルデバイドの影響を受ける集団への配慮が強調されている。

**原則6：応答性と持続可能性の促進（Promoting AI that is Responsive and Sustainable）**

AIシステムが社会のニーズに応答し、環境面を含む持続可能性に配慮することを求める。

<Callout type="info" title="WHOガイダンスの位置づけ">
WHOのガイダンスは法的拘束力を持たないが、加盟国の政策策定に大きな影響を与える。日本のAI事業者ガイドライン（2024年）も、WHOの6原則を参照している。
</Callout>

---

## WHOの大規模多様マルチモーダルモデル（LMM）ガイダンス

### LMM Guidance（2024年）

WHOは2024年1月、「Ethics and Governance of Large Multi-Modal Models（LMMs）」を公表した。ChatGPT、Claude、Geminiなどの大規模言語モデルの医療利用に特化した初の国際的ガイダンスである。

### LMM医療利用の5つのカテゴリー

WHOは、LMMの医療利用を以下の5カテゴリーに分類した。

1. **診断と臨床ケア**：症状の解釈、鑑別診断、治療提案
2. **患者ガイダンス**：健康情報の提供、セルフケアの助言
3. **事務・管理タスク**：診療録の作成、コーディング、請求処理
4. **医学教育と研修**：学生の教育、専門職のCPD
5. **科学研究**：文献レビュー、データ分析、仮説生成

### LMMに対するWHOの懸念事項

**ハルシネーション（Hallucination）**：LMMが事実でない情報を自信を持って生成するリスク。医療においては、誤った薬剤情報や治療法の生成が患者に直接的な害をもたらしうる。

**バイアスの増幅**：学習データに含まれるバイアスが医療推奨に反映されるリスク。特に、英語中心の学習データが非英語圏の医療文化や実践を正確に反映しない問題。

**プライバシーリスク**：医療従事者がLMMに患者情報を入力することによるデータ漏洩リスク。

**アクセシビリティの格差**：LMMの恩恵が先進国に集中し、LMICではインフラ・コスト・言語の壁により利用が制限される。

<Warning>
WHOは、LMMが医療における意思決定を完全に自動化することに対して明確に警告している。LMMの出力は常に医療専門家による検証を経るべきであり、「AIに任せる」ことは許容されない。
</Warning>

---

## UNESCOのAI倫理勧告

### Recommendation on the Ethics of Artificial Intelligence（2021年）

UNESCOは2021年11月、「AI倫理に関する勧告」を全会一致で採択した。193の加盟国が採択した、AIに関する初のグローバル規範文書である。

### 4つの価値と10の原則

**4つの価値（Values）**：
1. 人権と基本的自由の尊重
2. 環境と生態系の繁栄
3. 多様性と包摂性の確保
4. 平和で公正かつ相互に結びついた社会での生活

**10の原則（Principles）**：

<StepFlow>
<StepFlowStep number={1} title="比例性と無危害">
AIシステムの利用は、目的に対して比例的であり、害を最小化すべきである。
</StepFlowStep>
<StepFlowStep number={2} title="安全とセキュリティ">
AIの設計・運用において、不要なリスクを回避し、安全性を確保する。
</StepFlowStep>
<StepFlowStep number={3} title="公平性と非差別">
AIが個人や集団に対する差別を生じさせないことを確保する。
</StepFlowStep>
<StepFlowStep number={4} title="持続可能性">
AIシステムの環境への影響を継続的に評価し、持続可能性を促進する。
</StepFlowStep>
<StepFlowStep number={5} title="プライバシーとデータ保護">
個人データの保護とプライバシーの尊重を確保する。
</StepFlowStep>
<StepFlowStep number={6} title="人間の監視と決定">
AIシステムに対する人間のコントロールを維持し、最終的な意思決定を人間が行う。
</StepFlowStep>
<StepFlowStep number={7} title="透明性と説明可能性">
AIの動作を理解可能にし、意思決定プロセスを透明化する。
</StepFlowStep>
<StepFlowStep number={8} title="責任とアカウンタビリティ">
AIのライフサイクルに関わるすべてのアクターの責任を明確にする。
</StepFlowStep>
<StepFlowStep number={9} title="認識と素養">
AIリテラシーの向上と、AIに関する公的な議論の促進を図る。
</StepFlowStep>
<StepFlowStep number={10} title="マルチステークホルダーの適応的ガバナンス">
多様なステークホルダーの参加に基づく柔軟なガバナンス体制を構築する。
</StepFlowStep>
</StepFlow>

---

## OECDのAI原則

### OECD AI Principles（2019年、2024年改訂）

OECDは2019年に「AI原則」を採択し、2024年に改訂した。法的拘束力はないが、G7/G20を含む46カ国が支持しており、国際的に最も広く参照されるAI原則の一つである。

### 5つの原則

1. **包摂的成長、持続可能な発展、ウェルビーイング**
2. **人間中心の価値観と公平性**
3. **透明性と説明可能性**
4. **頑健性、セキュリティ、安全性**
5. **アカウンタビリティ**

### 医療分野への適用

OECDは2022年に「OECD Framework for the Classification of AI Systems」を公表し、AIシステムの分類フレームワークを提示した。このフレームワークでは、AIシステムの文脈（Context）、データとインプット（Data & Input）、AIモデル（AI Model）、タスクとアウトプット（Task & Output）の4次元でAIを分類する。

医療AIの場合、「文脈」の次元における「応用分野（Health）」「規制状況」「影響を受ける権利」の評価が特に重要になる。

---

## グローバルガバナンスの比較

<ComparisonCard
  title="主要な国際機関のAIガバナンスアプローチ"
  left={{
    title: "規範的アプローチ（WHO・UNESCO）",
    items: [
      "価値と原則を重視",
      "法的拘束力なし（ソフトロー）",
      "LMIC含むグローバル視点",
      "倫理的フレームワークの提供",
      "193カ国の合意形成"
    ]
  }}
  right={{
    title: "規制的アプローチ（EU・FDA）",
    items: [
      "具体的な要件と基準を重視",
      "法的拘束力あり（ハードロー）",
      "先進国中心の視点",
      "コンプライアンス枠組みの提供",
      "違反時の制裁措置"
    ]
  }}
/>

---

## 低中所得国（LMIC）と医療AI

### WHOの重点課題

WHOのガイダンスが他の規制文書と異なる最大の特徴は、低中所得国（Low- and Middle-Income Countries, LMIC）への配慮が全面に出ていることである。

### LMICにおける医療AIの課題

**インフラの不足**：インターネット接続、電力供給、コンピューティングリソースの不足が、AI導入の障壁となる。

**データの不足**：LMICの疾病パターン（熱帯病、マラリア、結核等）に関する質の高いデータが、AI学習用に十分に整備されていない。先進国のデータで学習されたAIが、LMICの患者に適用される場合の精度低下（domain shift）が懸念される。

**人材の不足**：AI を運用・監視できる医療専門家が不足している。

**規制能力の不足**：多くのLMICには、医療AIを適切に評価・規制する機関の能力が不足している。

### デジタル植民主義への警告

WHOとUNESCOは、先進国で開発されたAIがLMICに無批判に導入されることの危険性を「デジタル植民主義」として警告している。LMICの医療ニーズ、文化的文脈、倫理的価値観を無視したAI導入は、新たな形の依存関係を生む恐れがある。

<Callout type="warning" title="日本の医療AIとグローバルサウス">
日本の医療AI開発者がアジア・アフリカの市場への展開を検討する場合、WHOのLMICに関する指摘は特に重要である。日本人のデータで学習されたAIを、異なる人種構成・疾病パターン・医療体制の国に適用する際には、慎重な適応と検証が必要である。
</Callout>

---

## 日本への示唆

### 国際規範と国内政策の整合

日本政府のAI政策は、OECD AI原則を基盤としている。AI戦略会議による「AI事業者ガイドライン」（2024年4月）は、WHOの6原則やUNESCOの勧告とも整合的に策定されている。

しかし、国際規範と国内の実務の間にはギャップが存在する。医療現場でのAI利用に関する具体的なガイドラインは、各学会や医療機関の自主的な取り組みに委ねられている部分が大きい。

### グローバルヘルスへの貢献

日本は、国際保健分野でのODA（政府開発援助）の実績を活かし、LMICの医療AIガバナンス能力構築に貢献できる立場にある。具体的には以下の取り組みが考えられる。

- LMICの医療データ整備への技術支援
- 医療AI規制能力構築への人材支援
- 日本発の医療AIのLMIC適応に関する研究支援
- 国際機関（WHO、UNESCO）でのルール形成への積極的参画

---

## 今後の展望

### AI安全性サミットとブレッチリー宣言

2023年11月の英国AI安全性サミットでブレッチリー宣言が採択され、2024年にはソウルサミット、2025年にはパリサミットが開催された。フロンティアAIのリスク管理に関する国際協調が加速している。

### 国連のAIガバナンス

2024年には国連のAI諮問機関（AI Advisory Body）が最終報告書「Governing AI for Humanity」を公表し、グローバルなAIガバナンスの制度的枠組みを提言した。医療AIは、この枠組みの中で「高影響セクター」として位置づけられている。

### 規範の収斂

WHO、UNESCO、OECD、EU、各国政府の原則を見ると、以下の項目で国際的な収斂（convergence）が見られる。

- 透明性・説明可能性
- 人間の監視・コントロール
- 公平性・非差別
- アカウンタビリティ
- プライバシー保護
- 安全性の確保

<PromptTemplate title="グローバルAIガバナンス対応チェックリスト">
**WHOガイダンスへの適合**
- [ ] 6原則に基づく自己評価を実施した
- [ ] 人間の自律性の保護措置を確認した
- [ ] 包摂性と公平性の観点から製品を評価した
- [ ] LMMを使用する場合、WHOのLMMガイダンスを参照した

**国際規範への対応**
- [ ] OECD AI原則との整合性を確認した
- [ ] UNESCOの10原則を参照した
- [ ] 国際展開先の規制枠組みを調査した

**LMIC展開時の追加チェック**
- [ ] 対象国の疾病パターンとデータの代表性を検証した
- [ ] 現地の医療体制・文化的文脈を調査した
- [ ] 現地の規制枠組みと自社AIの適合性を確認した
- [ ] デジタル植民主義のリスクを評価した
</PromptTemplate>

<KeyTakeaway>
- WHOの医療AI倫理ガイダンス（2021年）は6原則を提示し、LMICを含むグローバルな視点が特徴
- WHOのLMMガイダンス（2024年）はLLMの医療利用に特化した初の国際的指針
- UNESCOの勧告（2021年）は193カ国が採択した初のグローバルAI倫理規範
- OECD AI原則（2019年、2024年改訂）は46カ国が支持する最も広く参照される原則
- 「透明性」「人間の監視」「公平性」「アカウンタビリティ」は国際的に収斂する共通原則
- LMICにおける医療AIの課題（インフラ、データ、人材、規制能力の不足）への配慮が不可欠
- 日本はグローバルヘルスへの貢献と国際ルール形成への積極的参画が求められる
</KeyTakeaway>
