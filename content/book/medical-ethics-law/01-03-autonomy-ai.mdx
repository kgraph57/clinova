---
title: "患者の自律性とAI意思決定支援の境界"
description: "AIによる意思決定支援は、患者の自律性を拡張するのか、それとも侵食するのか。境界線の設計と実践的対応策を論じる。"
slug: "01-03-autonomy-ai"
order: 3
partId: "part01"
partTitle: "医療倫理の基盤"
partOrder: 1
estimatedMinutes: 20
free: true
status: "published"
tags: ["自律性", "意思決定支援", "パターナリズム", "ナッジ", "共同意思決定", "SDM"]
publishedAt: "2026-03-01"
updatedAt: "2026-03-01"
---

**AIは患者の意思決定を「支援」するのか、それとも「誘導」するのか。この区別こそが、AI時代の患者自律性の核心である。**

---

## 患者の自律性とは何か

患者の自律性（patient autonomy）は、近代医療倫理の中核概念である。その内容は以下の3要素に分解される。

1. **意図性**（intentionality）：患者が自分の意思で行動している
2. **理解**（understanding）：患者が行動の意味と結果を理解している
3. **外的支配の不在**（absence of controlling influences）：外部からの不当な支配や操作がない

ビーチャム＆チルドレスは、完全な自律性は理想型であり、実際には「実質的自律性」（substantial autonomy）で十分であるとした。しかし、AIの介在がこの「実質的自律性」さえも脅かしうることが、新たな問題として浮上している。

---

## 3つのモデル：パターナリズム、自律尊重、共同意思決定

### パターナリズムモデル

医師が患者の最善の利益を判断し、患者はそれに従う。日本の医療は長くこのモデルが支配的であった。「先生にお任せします」という患者の態度は、このモデルの反映である。

### 自律尊重モデル

患者が十分な情報に基づき自ら意思決定を行い、医師はそれを尊重する。米国を中心に発展したモデルであり、インフォームドコンセントの法的整備と共に普及した。

### 共同意思決定モデル（SDM: Shared Decision Making）

医師と患者が対話を通じて共同で意思決定を行う。医師は専門的知識を、患者は自身の価値観・選好を提供し、両者が合意に至るプロセスを重視する。現在の医療倫理の主流モデルである。

<Callout type="info" title="AIはどのモデルに位置づけられるか">
AIは、表面的には「客観的情報の提供」であり、自律尊重モデルに親和的に見える。しかし、AIの推奨には暗黙の価値判断が埋め込まれており、パターナリズム的に機能するリスクがある。SDMモデルの枠組みでAIを位置づけることが適切である。
</Callout>

---

## AIによる自律性への脅威

### 脅威1：アンカリング効果

AIが最初に診断候補や治療推奨を提示すると、医師も患者もその情報に「アンカー」（錨）を下ろしてしまう心理的傾向がある。これは認知バイアスの一種であるアンカリング効果である。

**事例**：AIが「肺炎の可能性85%」と表示した場合、医師は肺炎以外の診断を十分に検討しなくなり、患者への説明も肺炎中心になる。患者は他の可能性を検討する機会を失う。

2025年のJAMA RCTでは、AI支援を受けた医師がAIのアンカリングに引きずられ、かえって診断精度が低下したことが示されている。

### 脅威2：デフォルト効果

AIの推奨がデフォルト（初期設定）として提示された場合、人間はデフォルトから逸脱することに心理的抵抗を感じる。行動経済学では、これをデフォルト効果（default effect）と呼ぶ。

**事例**：AI搭載の電子カルテが「推奨処方：アムロジピン5mg」をデフォルト表示した場合、医師はその処方を変更するよりも、そのまま採用する傾向が強まる。患者は処方がAIのデフォルト推奨であることを知らない。

### 脅威3：権威バイアス

「AIが言っている」という事実が、権威バイアスとして機能する。特にAIの精度が高いと喧伝されている場合、医師も患者もAIの判断に逆らうことに躊躇する。

**事例**：AIが「悪性の可能性は低い」と判断した所見について、経験豊富な放射線科医が違和感を覚えたとしても、「AIが良性と言っているのに、自分の直感を優先して侵襲的な精査を勧めてよいのか」と躊躇する状況。

### 脅威4：情報過多による選択麻痺

AIが大量の情報を患者に提供した場合、かえって意思決定が困難になる。選択肢が多すぎると決められなくなる「選択のパラドックス」（Barry Schwartz）が、AIの情報提供でも起こりうる。

<StatHighlight value="85%" label="の人がデフォルト選択肢をそのまま採用する" source="Johnson & Goldstein, Science, 2003" />

---

## 自律性を守るための設計原則

### 原則1：Human-in-the-Loop（人間参加型）の徹底

AIの出力は常に「提案」であり、「決定」ではないことを、システム設計レベルで担保する。

- AIの画面表示に「これは参考情報です。最終判断は医師と患者で行ってください」という注記を常に表示する
- AIの推奨を自動的に実行するワークフローを避ける（例：AI推奨処方の自動オーダーは不可）
- 医師がAI推奨を採用しない場合、理由を記録する仕組みを設ける（ただし、AI推奨を拒否すること自体をハードルにしない）

### 原則2：ナッジの透明性

AIの推奨が患者の意思決定にナッジとして影響しうることを認識し、以下の対策を講じる。

- AI推奨と同等の重みで代替選択肢を提示する
- AI推奨の根拠と不確実性を明示する
- 患者が「AI推奨に従わない」選択を容易にする

### 原則3：段階的自律性支援

すべての患者に同じレベルの情報提供が適切とは限らない。患者の意思決定能力、情報ニーズ、感情的状態に応じて、段階的な自律性支援を行う。

<ComparisonCard
  title="AIの意思決定支援：適切な境界"
  left={{
    title: "自律性を支援する",
    items: [
      "選択肢と根拠の提示",
      "不確実性の明示",
      "患者の価値観を反映",
      "拒否する自由を保障",
      "医師-患者対話を促進"
    ]
  }}
  right={{
    title: "自律性を侵害する",
    items: [
      "単一の推奨のみ表示",
      "確定的な表現",
      "統計的最適のみ追求",
      "拒否にハードルを設定",
      "AI出力が対話を代替"
    ]
  }}
/>

---

## 共同意思決定（SDM）モデルにおけるAIの位置づけ

共同意思決定（SDM）は、医師と患者の対話を通じて治療方針を決定するモデルである。このモデルにAIを組み込む場合、AIの役割を明確に位置づける必要がある。

### AIの適切な役割

1. **情報提供者**：エビデンスに基づく選択肢とそのリスク・ベネフィットを整理して提示する
2. **意思決定支援ツール**：患者の価値観や選好を構造化し、治療選択肢との照合を支援する
3. **コミュニケーション支援**：医学的情報を患者が理解しやすい形に変換する

### AIが担うべきでない役割

1. **意思決定者**：最終的な意思決定をAIに委ねてはならない
2. **価値判断者**：患者にとって何が「良い」かの価値判断をAIが行うべきではない
3. **説得者**：特定の治療法を患者に「説得」する役割をAIに持たせるべきではない

---

## ケーススタディ：がん治療の意思決定

### 状況

65歳男性、Stage II大腸がんと診断。AIシステムが3つの治療選択肢を分析し、それぞれの5年生存率、副作用リスク、QOL影響を提示した。

- 選択肢A（手術＋化学療法）：5年生存率82%、QOLスコア中
- 選択肢B（手術のみ）：5年生存率75%、QOLスコア高
- 選択肢C（化学放射線療法）：5年生存率78%、QOLスコア低

AIは「選択肢Aを推奨」と表示。

### 問題点の分析

1. AIは5年生存率を最重要指標として推奨を出している。しかし、この患者にとってQOLが最も重要かもしれない
2. AI推奨が一つに絞られており、3つの選択肢を等しく検討する機会を損なっている
3. 患者の個人的事情（家族構成、仕事、趣味、人生観）がAIの分析に含まれていない

### 適切な対応

1. AIの分析結果を「3つの選択肢の比較表」として提示する（特定の推奨を強調しない）
2. 患者に「何を最も大切にしたいか」を尋ねる（生存期間、QOL、副作用の許容度など）
3. 患者の価値観に基づいて、医師と患者で共同で意思決定を行う
4. AI推奨と異なる選択をした場合も、それが患者の自律的決定として尊重される

---

## 脆弱な患者の自律性保護

### 高齢者

高齢者はAIに対して過度の信頼（「コンピュータが言うなら正しいだろう」）または過度の不信（「機械に判断されたくない」）を持ちやすい。いずれの場合も、患者の真の意思を丁寧に確認する必要がある。

### 精神疾患を持つ患者

抑うつや不安障害の患者は、AIの推奨に対して過度に従順になる、または過度に拒絶的になる可能性がある。患者の心理状態を考慮した上で、自律的意思決定を支援する必要がある。

### 言語的マイノリティ

日本語を母語としない患者に対するAIの説明は、言語的・文化的に適切である必要がある。AI翻訳の利用は有用だが、その正確性の検証が必要である。

---

## 「自律性のスペクトラム」モデル

自律性は「ある/なし」の二値ではなく、スペクトラム（連続体）として捉えるべきである。

<StepFlow>
<StepFlowStep number={1} title="完全なパターナリズム">
医師（またはAI）がすべてを決定。患者の意思は考慮されない。倫理的に不適切。
</StepFlowStep>
<StepFlowStep number={2} title="誘導型支援">
AIが強く推奨し、患者は追認する。形式上は同意があるが、実質的自律性は低い。
</StepFlowStep>
<StepFlowStep number={3} title="情報提供型支援（推奨）">
AIが情報と選択肢を提示し、医師が説明を加え、患者が主体的に選択する。SDMモデル。
</StepFlowStep>
<StepFlowStep number={4} title="完全な自律">
患者がすべてを単独で決定。医師は助言のみ。情報量が膨大な場合、かえって決定が困難になるリスク。
</StepFlowStep>
</StepFlow>

多くの臨床場面において、**ステップ3の「情報提供型支援」が最も適切なバランス**である。AIは患者の自律性を「支配」するのでも「放任」するのでもなく、「支援」する位置に置かれるべきである。

---

## 自律性保護のための組織的対策

個々の医師の努力だけでなく、組織レベルでの対策が必要である。

1. **AI利用ガイドラインの策定**：自律性保護の観点を含むガイドラインの策定
2. **研修プログラム**：AIの心理的影響（アンカリング効果、デフォルト効果等）に関する医師への研修
3. **患者向け教育資料**：AIの役割と限界を分かりやすく説明する資料の整備
4. **UI/UXの倫理的設計**：AI推奨が過度に目立たない、代替案も同等に表示される等のインターフェース設計
5. **監査と評価**：AIが患者の意思決定に与える影響の定期的な評価

<KeyTakeaway>
- 患者の自律性は意図性・理解・外的支配の不在の3要素で構成される。AIはすべての要素に影響を与えうる
- AIはアンカリング効果、デフォルト効果、権威バイアス、情報過多を通じて自律性を脅かす
- 共同意思決定（SDM）モデルにおいて、AIは「情報提供者」「意思決定支援ツール」に位置づけるべき
- Human-in-the-Loop、ナッジの透明性、段階的自律性支援が設計原則として重要
- 「情報提供型支援」が自律性のスペクトラム上で最も適切なバランスであり、AIは自律性を「支配」でも「放任」でもなく「支援」すべきである
- 脆弱な患者（高齢者、精神疾患、言語的マイノリティ）の自律性保護に特別な配慮が必要
</KeyTakeaway>
