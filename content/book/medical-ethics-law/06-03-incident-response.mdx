---
title: "AIインシデント対応プロトコル"
description: "医療AIに関連するインシデントの分類、初動対応、原因分析、再発防止策まで。"
slug: "06-03-incident-response"
order: 20
partId: "part06"
partTitle: "組織ガバナンス"
partOrder: 3
estimatedMinutes: 20
free: false
status: "published"
tags: ["インシデント", "対応", "報告", "医療安全"]
publishedAt: "2026-03-01"
updatedAt: "2026-03-01"
---

**AIインシデントは「起こるかどうか」ではなく「いつ起こるか」の問題である。**

---

## AIインシデントの定義と分類

AIインシデントとは、AIの利用に関連して、患者安全・個人情報保護・診療の質に影響を及ぼした、または及ぼす可能性のあった事象をいう。

### 重大度分類

| レベル | 分類 | 定義 | 対応期限 |
|--------|------|------|---------|
| 1 | 重大 | 患者への直接的な健康被害が発生 | 即座 |
| 2 | 中等度 | 患者データの外部流出、誤診に至る可能性 | 24時間以内 |
| 3 | 軽微 | ヒヤリ・ハット、手順違反（実害なし） | 1週間以内 |
| 4 | 注意 | ポリシー違反の発見（リスクは極めて低い） | 次回委員会 |

<Warning level="high">レベル1・2のインシデントは、発見者が直ちに医療安全管理者に報告すること。</Warning>

---

## AIインシデントの類型

### 類型1: 患者データの意図しない外部送信

医師がChatGPTに患者の検査結果を入力。入力データに患者の氏名・IDが含まれていた。

### 類型2: AI出力の無検証での臨床利用

AIが提案した薬剤量をそのまま処方したが、年齢・体重に基づく用量調整が反映されていなかった。

### 類型3: AIハルシネーションに基づく判断

AIが「このガイドラインでは〇〇を推奨」と出力したが、該当ガイドラインにそのような記載は存在しなかった。

### 類型4: AI利用の不適切な開示

患者への説明時に「AIが診断しました」と伝え、AIへの過度な依存と受け取られた。

---

## 初動対応フロー

<StepFlow title="AIインシデント初動対応">
  <StepFlowStep number={1} title="発見・認識" time="即座">
    インシデントを発見したら、まず患者の安全を確保する。
  </StepFlowStep>
  <StepFlowStep number={2} title="応急措置" time="即座">
    AI出力に基づく誤った処方・処置があれば直ちに是正。データ流出時はアカウント利用停止。
  </StepFlowStep>
  <StepFlowStep number={3} title="報告" time="重大度に応じて">
    医療安全管理室に報告。レベル1-2は口頭で即時、レベル3-4は書面で所定期限内。
  </StepFlowStep>
  <StepFlowStep number={4} title="記録" time="24時間以内">
    インシデント報告書を作成。AI利用の詳細を記録。
  </StepFlowStep>
  <StepFlowStep number={5} title="原因分析" time="1週間以内">
    RCA（Root Cause Analysis）を実施。
  </StepFlowStep>
</StepFlow>

---

## インシデント報告テンプレート

<PromptTemplate>
【AIインシデント報告書】
報告日:
報告者（匿名可）:
発生日時:
重大度レベル: □1(重大) □2(中等度) □3(軽微) □4(注意)

■ インシデント概要
- 使用したAIツール名:
- 利用目的:
- AIへの入力内容（概要）:
- AIの出力内容（概要）:
- 何が問題だったか:

■ 患者への影響: □あり □なし □不明

■ 応急措置の内容:

■ 個人情報関連
- 患者データの外部送信: □あり □なし

■ 発生要因（推定）
□ポリシーの不知 □手順の不備 □確認不足 □システム要因 □その他

■ 再発防止策（提案）:
</PromptTemplate>

---

## 原因分析（RCA）の3層フレームワーク

**1. 個人レベル**: AI利用の知識・スキル、ポリシー理解度、確認手順の実施

**2. チーム・部門レベル**: ルール共有状況、ダブルチェック体制、業務負荷

**3. 組織・システムレベル**: ポリシーの明確さ、技術的安全策、教育・研修の充実度

<Callout>RCAの目的は「誰が悪いか」ではなく「なぜ起きたか」「どうすれば防げるか」を明らかにすることである。</Callout>

---

## 再発防止策の階層

1. **システム的対策**（最も効果的）: 患者データの外部送信を技術的にブロック
2. **プロセス改善**: チェックリスト導入、ダブルチェック体制
3. **教育・啓発**: 事例共有、追加研修（単独では不十分）

<Warning level="medium">「注意喚起」だけの再発防止策は効果が限定的。必ずシステム的対策と組み合わせること。</Warning>

---

## 外部報告が必要な場合

- **個人情報保護委員会**: 個人データの漏えい等（改正個人情報保護法第26条）
- **厚生労働省**: 医療事故に該当する場合（医療法第6条の10）
- **PMDA**: 承認済み医療AI（SaMD）に起因する場合
- **患者本人**: 個人データの漏えいの場合、本人への通知義務あり

---

## まとめ

<KeyTakeaway>
- AIインシデントは4段階の重大度で分類し、対応期限を明確にする
- 初動対応では患者安全の確保を最優先とする
- RCAは個人・チーム・組織の3層で実施する
- 再発防止策はシステム的対策を最優先とし、教育だけに頼らない
- 個人情報漏えいの場合は個人情報保護委員会への報告義務がある
- 非懲罰的な報告文化の醸成が組織学習の鍵である
</KeyTakeaway>
