---
title: "院内AI利用ポリシーの策定"
description: "医療機関におけるAI利用ポリシーの策定方法。実用テンプレート付きで解説。"
slug: "06-02-policy-template"
order: 19
partId: "part06"
partTitle: "組織ガバナンス"
partOrder: 2
estimatedMinutes: 20
free: false
status: "published"
tags: ["ポリシー", "テンプレート", "院内規定", "ガバナンス"]
publishedAt: "2026-03-01"
updatedAt: "2026-03-01"
---

**ポリシーなきAI利用は、組織リスクの温床である。**

---

## なぜ院内AI利用ポリシーが必要か

2025年時点で、AI（特にChatGPTやClaude等の生成AI）を業務で利用する医療者は急増している。しかし、多くの医療機関では明確な利用ポリシーが存在しない。

<StatHighlight stat="78%" context="医療機関のうち、生成AI利用ポリシーを持たない割合" source="HIMSS 2025 Survey" />

ポリシーがない場合に起こりうるリスク:

- **患者データの外部流出**: ChatGPTに患者情報をそのまま入力
- **誤診・誤判断**: AI出力の無検証での利用
- **法的責任の不明確さ**: 問題発生時の責任所在が不明
- **職員間の不公平**: 利用者と非利用者の業務効率格差

<Warning level="high">ポリシーの不在は「暗黙の許可」と解釈されうる。明文化された規定がなければ、インシデント発生時に組織として対応できない。</Warning>

---

## ポリシー策定の5ステップ

<StepFlow title="AI利用ポリシー策定プロセス">
  <StepFlowStep number={1} title="現状調査" time="2週間">
    院内でのAI利用実態を匿名アンケートで把握する。
  </StepFlowStep>
  <StepFlowStep number={2} title="リスク評価" time="2週間">
    利用シーン別にリスクを評価し、許可・条件付き許可・禁止を分類する。
  </StepFlowStep>
  <StepFlowStep number={3} title="ドラフト作成" time="2週間">
    ポリシー本文と関連様式（申請書・チェックリスト等）を起草する。
  </StepFlowStep>
  <StepFlowStep number={4} title="関係者レビュー" time="2週間">
    医療安全、情報セキュリティ、法務、各診療科の代表者でレビューする。
  </StepFlowStep>
  <StepFlowStep number={5} title="承認・周知・教育" time="2週間">
    病院長承認→全職員周知→教育研修の実施。
  </StepFlowStep>
</StepFlow>

---

## AI利用ポリシー テンプレート（全文）

以下は、中規模病院（200-500床）を想定したポリシーテンプレートである。

### 第1条（目的）

本ポリシーは、当院における人工知能（AI）ツールの利用に関する基本方針を定め、患者安全の確保、個人情報の保護、および診療の質向上を目的とする。

### 第2条（適用範囲）

当院の全職員（常勤・非常勤・委託業者・研修医・学生を含む）が業務において利用するすべてのAIツールに適用される。

<Callout>「業務における利用」には、私用端末で院内業務に関連してAIを利用する場合も含まれる。</Callout>

### 第3条（定義）

- **AIツール**: 機械学習・深層学習・大規模言語モデル等を基盤とするソフトウェア
- **生成AI**: テキスト等を生成するAIサービス（ChatGPT, Claude, Gemini等）
- **医療AI**: 薬機法に基づく承認を受けた医療機器としてのAIプログラム
- **患者データ**: 個人情報保護法第2条に定める個人情報のうち、診療に関するもの

### 第4条（許可されるAI利用）

1. 医学文献の検索・要約・翻訳
2. 一般的な医学知識に関する質問応答（患者情報を含まないもの）
3. 業務文書の作成補助
4. 承認済み医療AIの添付文書に基づく使用
5. 匿名化された症例に基づく教育目的の利用

### 第5条（条件付きで許可されるAI利用）

所属長の承認を得た上で許可:
1. 仮名加工情報を用いた研究目的のAI利用
2. 院内オンプレミス環境でのAI利用
3. 患者説明資料の作成（医師の最終確認を条件）

### 第6条（禁止されるAI利用）

1. **患者の個人情報を外部AIサービスに入力すること**
2. AI出力を検証なしに診療判断に用いること
3. AI出力をそのまま診療録に記載すること
4. AI生成コンテンツを自己の著作として発表すること
5. 未承認の医療AIを診療目的で使用すること

<Warning level="high">第6条第1号違反は個人情報保護法違反となる可能性がある。</Warning>

### 第7条（データ取扱い規定）

外部AIサービスへの入力は完全に匿名化されたデータに限る。

### 第8条（AI出力の検証義務）

AI出力を臨床判断の参考とする場合、必ず根拠の確認を行う。

### 第9条（インシデント報告）

AI利用に関連するインシデントが発生した場合、医療安全管理室に速やかに報告する。

### 第10条（教育義務）

全職員は年1回のAIリテラシー研修を受講すること。

### 第11条（見直し）

少なくとも年1回見直しを行う。

---

## ポリシー付属様式

### 様式1: AI利用チェックリスト

<PromptTemplate>
□ 入力データに患者の個人情報が含まれていないか
□ 利用目的は第4条に該当するか
□ 条件付き許可の場合、所属長の承認を得たか
□ AI出力の根拠を確認したか
□ 最終判断は自身の責任で行ったか
</PromptTemplate>

### 様式2: AI利用申請書

<PromptTemplate>
【AI利用申請書】
申請者:
所属:
申請日:
1. 利用するAIツール名:
2. 利用目的:
3. 入力するデータの種類:
4. 匿名化の方法:
5. 利用期間:
6. 想定されるリスクと対策:
所属長承認: □ 承認 □ 不承認
</PromptTemplate>

---

## まとめ

<KeyTakeaway>
- 院内AI利用ポリシーは患者安全・個人情報保護・法的リスク管理の基盤
- 許可・条件付き許可・禁止の3段階で利用シーンを分類する
- 患者個人情報の外部AI入力は絶対禁止とし全職員に周知
- シンプルに始めて段階的に改善するアプローチが実効性が高い
- 年1回以上の見直しと全職員教育を制度化する
</KeyTakeaway>
