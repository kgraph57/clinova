---
title: "EU AI Act — 医療AIへの影響"
description: "2024年に成立したEU AI Actのリスクベースアプローチと、医療AIが受ける規制の内容を詳解する。"
slug: "04-01-eu-ai-act"
order: 12
partId: "part04"
partTitle: "世界の規制動向"
partOrder: 1
estimatedMinutes: 22
free: false
status: "published"
tags: ["EU AI Act", "欧州連合", "リスクベース", "高リスクAI", "CE マーキング", "GDPR"]
publishedAt: "2026-03-01"
updatedAt: "2026-03-01"
---

**2024年8月に発効したEU AI Actは、AIに対する世界初の包括的規制法である。医療AIは「高リスクAI」に分類され、最も厳格な要件が課される。EU域外の開発者・医療機関であっても、EU市場への影響がある場合は適用を受ける。**

---

## EU AI Actの概要

### 立法の経緯

EU AI Actは、欧州委員会が2021年4月に提案し、欧州議会と理事会の三者間協議（トリローグ）を経て、2024年3月に最終合意に達した。2024年8月1日に発効し、段階的に施行される。

**施行スケジュール**：
- 2024年8月1日：発効
- 2025年2月：禁止されるAI慣行に関する規定の適用開始
- 2025年8月：汎用AIモデル（GPAI）に関する規定の適用開始
- 2026年8月：高リスクAIシステムに関する規定の完全適用

### 規制の目的

EU AI Actは、以下の3つの目的を掲げている。

1. **安全性の確保**：AIシステムが基本的権利と安全性を尊重することを保証する
2. **イノベーションの促進**：信頼できるAIの開発と普及を促進する
3. **法的確実性**：AI開発者と利用者に明確な法的枠組みを提供する

<Callout type="info" title="GDPRとの関係">
EU AI ActはGDPR（General Data Protection Regulation）を補完する位置づけにある。GDPRが「データ」の保護を目的とするのに対し、EU AI Actは「AIシステム」の安全性と透明性を規制する。医療AIの場合、両方の規制が同時に適用される。
</Callout>

---

## リスクベースアプローチ

### 4段階のリスク分類

EU AI Actの核心は、AIシステムをリスクに応じて4段階に分類し、リスクが高いほど厳格な規制を課す「リスクベースアプローチ」にある。

**1. 禁止リスク（Unacceptable Risk）**

EU の価値観と基本的権利に反するとみなされるAIシステム。開発・導入が禁止される。

- ソーシャルスコアリング（社会的信用スコア）
- 公共空間でのリアルタイム遠隔生体認証（例外あり）
- 感情認識AI（職場・教育機関での使用）
- サブリミナル技術を用いた操作的AI

**2. 高リスク（High Risk）**

基本的権利、安全性、健康に重大な影響を及ぼしうるAIシステム。厳格な要件が課される。

- **医療機器AIはここに分類される**
- 生体認証・分類システム
- 重要インフラの管理
- 教育・雇用におけるAI
- 法執行・司法におけるAI

**3. 限定リスク（Limited Risk）**

透明性義務が課されるAIシステム。

- チャットボット（AI であることの開示義務）
- 感情認識システム
- ディープフェイク生成システム

**4. 最小リスク（Minimal Risk）**

特段の規制なし。EU AI Actの規制対象外。

- スパムフィルター
- AIを使ったゲーム
- 在庫管理AI

<ComparisonCard
  title="EU AI Act リスク分類と医療AIの位置づけ"
  left={{
    title: "高リスクに分類される医療AI",
    items: [
      "診断支援AI（画像診断、病理診断）",
      "治療計画策定AI",
      "トリアージAI",
      "医療機器としてのSaMD",
      "生体認証に基づく患者識別"
    ]
  }}
  right={{
    title: "限定リスクまたは最小リスク",
    items: [
      "医療機関のチャットボット（予約等）",
      "事務処理の自動化AI",
      "文献検索AI",
      "レセプト処理AI",
      "施設管理AI"
    ]
  }}
/>

---

## 高リスクAIに課される要件

医療AIが高リスクに分類された場合、以下の要件を満たす必要がある。

### 要件1：リスク管理システム（第9条）

AIシステムのライフサイクル全体を通じた継続的なリスク管理プロセスの確立が求められる。

- 既知および予見可能なリスクの特定と分析
- リスクの推定と評価
- 適切なリスク軽減措置の採用
- 残存リスクの評価と許容判断

### 要件2：データガバナンス（第10条）

学習データ、検証データ、テストデータに対する厳格なガバナンスが求められる。

- データセットの適切な設計と文書化
- データの品質基準の設定
- データのバイアス検出と緩和
- データの代表性の確保

### 要件3：技術文書（第11条）

AIシステムの設計、開発、テストに関する包括的な技術文書の作成と維持が求められる。

### 要件4：記録保持（第12条）

AIシステムの動作ログの自動記録と保持が求められる。トレーサビリティの確保が目的。

### 要件5：透明性と情報提供（第13条）

利用者に対する適切な情報提供が求められる。

- AIシステムの意図された目的
- 精度、頑健性、サイバーセキュリティのレベル
- 既知の限界と制約
- 人間による監視の方法

### 要件6：人間による監視（第14条）

高リスクAIシステムには、人間による効果的な監視が可能な設計が求められる（Human Oversight）。

- AIの出力を理解し、解釈する能力
- AIの推奨を無視する能力（override）
- AIの動作を中断・停止する能力

### 要件7：精度、頑健性、サイバーセキュリティ（第15条）

適切なレベルの精度、頑健性、サイバーセキュリティの確保が求められる。

<Warning>
EU AI Actの違反に対する制裁金は極めて高額である。禁止されたAI慣行の違反は最大3,500万ユーロまたは全世界年間売上高の7%（いずれか高い方）、高リスクAIの要件違反は最大1,500万ユーロまたは全世界年間売上高の3%が科される。
</Warning>

---

## 医療AIへの具体的影響

### CE マーキングとの関係

EU域内で医療機器を販売するためには、CE マーキングが必要である。医療AIの場合、EU MDR（Medical Device Regulation, 2017/745）に基づくCE マーキングに加え、EU AI Actの要件も満たす必要がある。

両規制の要件は重複する部分があるが、EU AI Actは以下の追加的要件を課す。

- より広範なリスク管理の対象
- より厳格なデータガバナンス要件
- 人間による監視（Human Oversight）の明示的要件
- 基本的権利への影響評価

### 汎用AIモデル（GPAI）と医療

GPT-4やClaude等の汎用AIモデル（General-Purpose AI Model）は、EU AI Actの独立した規制カテゴリーに含まれる。GPAIプロバイダーには以下の義務が課される。

- 技術文書の作成
- 著作権法遵守の情報提供
- トレーニングデータの要約の公開

**システミックリスクのあるGPAI**（FLOPS基準等で判定）には追加義務が課される。

- モデル評価の実施
- システミックリスクの評価と軽減
- インシデント報告

<Callout type="warning" title="GPAIの医療利用への影響">
汎用LLMを医療相談や診断支援に使用する場合、GPAIの規制と高リスクAIの規制が重畳的に適用される可能性がある。EU域内での医療LLMの提供は、二重の規制遵守が必要になる場面が想定される。
</Callout>

---

## 日本の医療AI開発者への影響

### 域外適用

EU AI Actは、EU域外の事業者であっても、AIシステムの出力がEU域内で使用される場合に適用される（第2条）。日本で開発された医療AIであっても、EU域内の医療機関で使用される場合やEU市民の医療データを処理する場合には、EU AI Actの遵守が求められる。

### 対応のポイント

<StepFlow>
<StepFlowStep number={1} title="リスク分類の確認">
自社の医療AIがEU AI Actのどのリスクカテゴリーに該当するかを確認する。医療機器AIの場合、大半は高リスクに分類される。
</StepFlowStep>
<StepFlowStep number={2} title="ギャップ分析">
日本の薬機法・PMDA要件と、EU AI Actの要件を比較し、追加的に対応すべき事項を特定する。特に「人間による監視」「データガバナンス」「基本的権利影響評価」の追加要件に注意。
</StepFlowStep>
<StepFlowStep number={3} title="技術文書の整備">
EU AI Actが求める技術文書を整備する。既存のISO 13485やIEC 62304の文書体系を拡張する形で対応できる部分も多い。
</StepFlowStep>
<StepFlowStep number={4} title="適合性評価">
EU MDRのNotified Bodyによる適合性評価と、EU AI Actの適合性評価の両方を受ける。
</StepFlowStep>
</StepFlow>

---

## 他のAI規制との比較

### EU AI Act vs 日本のAI規制

日本は2024年時点で、AIに特化した包括的な法律を持たない。日本政府は「AI事業者ガイドライン」（2024年4月策定）を通じた「ソフトロー」アプローチを採用しており、EU AI Actのような「ハードロー」アプローチとは対照的である。

### EU AI Act vs 米国のAI規制

米国も連邦レベルでの包括的AI法は制定されていないが、大統領令（Executive Order on AI Safety, 2023年10月）や各州法（カリフォルニア州のSB 1047等）による分散的な規制が進行している。

<PromptTemplate title="EU AI Act 高リスクAI対応チェックリスト">
**リスク管理**
- [ ] AIシステムのリスク管理プロセスを文書化した
- [ ] 既知のリスクと緩和措置を一覧化した
- [ ] 残存リスクの許容性を評価した

**データガバナンス**
- [ ] 学習データの品質基準を設定した
- [ ] データのバイアス検出・緩和措置を実施した
- [ ] データセットの代表性を検証した

**透明性と人間監視**
- [ ] 利用者向け情報文書（使用説明書）を作成した
- [ ] AIの限界と制約を明記した
- [ ] 人間による監視（override機能）を実装した

**適合性評価**
- [ ] EU MDRとEU AI Actの両方の適合性評価計画を策定した
- [ ] 技術文書を整備した
- [ ] 動作ログの記録・保持の仕組みを実装した
</PromptTemplate>

<KeyTakeaway>
- EU AI Act（2024年8月発効）は世界初のAI包括規制法であり、リスクベースアプローチを採用
- 医療AIは「高リスクAI」に分類され、リスク管理・データガバナンス・透明性・人間監視等の厳格な要件が課される
- 制裁金は最大3,500万ユーロまたは全世界年間売上高の7%と極めて高額
- 域外適用があるため、EU市場に医療AIを提供する日本の開発者も遵守が必要
- EU MDR（医療機器規則）とEU AI Actの二重遵守が求められる
- 汎用AIモデル（GPAI）の医療利用には、追加的な規制層が存在する
- 日本のソフトローアプローチとEUのハードローアプローチの違いを理解した上で、国際展開戦略を構築すべき
</KeyTakeaway>
