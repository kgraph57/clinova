---
title: "CNN（畳み込みニューラルネットワーク）の基礎"
description: "画像認識の中核技術CNNの構造—畳み込み層・プーリング層・全結合層の仕組み、学習プロセス、医療画像への適用と限界を理解します"
order: 3
estimatedMinutes: 20
---

## CNNとは何か

CNN（Convolutional Neural Network：畳み込みニューラルネットワーク）は、画像認識に特化した深層学習アーキテクチャです。人間の視覚野の階層的な情報処理に着想を得て設計されました。

### 従来のニューラルネットワークとの違い

全結合型ニューラルネットワーク（MLP）と比較すると、CNNには以下の構造的な優位性があります。

- **局所的な特徴抽出** — フィルタ（カーネル）が画像の局所領域を走査し、パターンを認識する
- **位置不変性** — 同じ特徴が画像内のどこに現れても検出できる（プーリングにより強化）
- **パラメータ効率** — 重み共有により、全結合層に比べてパラメータ数が大幅に少ない
- **階層的な特徴学習** — 浅い層でエッジやテクスチャ、深い層で臓器や病変といった高次特徴を学習

<Callout type="insight" title="CNNの「目」はどう見ているか">
CNNの浅い層は線や角、テクスチャといった低レベル特徴を捉えます。中間層ではそれらが組み合わされて形状やパターンになり、深い層では「肺結節らしい丸い陰影」「骨折線」のような高レベルな概念を表現します。この階層構造が、医療画像の微細な病変検出に威力を発揮します。
</Callout>

---

## CNNの基本構造

### 畳み込み層（Convolutional Layer）

畳み込み層はCNNの中核です。小さなフィルタ（通常3×3や5×5）が画像上を走査し、特徴マップを生成します。

**構成要素:**

- **フィルタ（カーネル）** — 学習可能な小行列。各フィルタは特定のパターン（エッジ、テクスチャなど）に反応する
- **特徴マップ** — フィルタの応答を空間的に記録した出力。フィルタの数だけ特徴マップが生成される
- **ストライド** — フィルタを移動させる間隔。ストライド2では出力サイズが半分になる
- **パディング** — 画像の端を0やミラーで埋め、出力サイズを調整する

**活性化関数:**
畳み込み後にはReLU（Rectified Linear Unit）などの非線形関数を適用します。非線形性を導入することで、CNNは複雑なパターンを学習可能になります。

### プーリング層（Pooling Layer）

プーリング層は特徴マップの空間サイズを削減します。

**Max Pooling:**
局所領域内の最大値を選択します。最も一般的で、顕著な特徴を保持しつつサイズを縮小します。2×2のMax Poolingでは空間サイズが半分になります。

**Average Pooling:**
局所領域内の平均値を計算します。最終層でGlobal Average Poolingとして使われることが多く、全結合層の代替としても機能します。

**プーリングの効果:**
- 計算量の削減（次の層への入力サイズが減少）
- 微小な位置変動への頑健性の向上
- 過学習のリスク低減

### 全結合層（Fully Connected Layer）

畳み込み層とプーリング層で抽出された特徴を統合し、最終的な判断（分類や回帰）を行います。

- 特徴マップを1次元ベクトルに平坦化（Flatten）
- 1つ以上の全結合層を通過
- 出力層でSoftmax（分類）やSigmoid（二値分類）を適用

<Callout type="comparison" title="CNNの典型的な構成">
入力 → [畳み込み → ReLU → プーリング] × N回 → Flatten → 全結合層 → 出力。この基本パターンはVGGやResNetなど多くのモデルに共通します。Nの深さやフィルタ数がモデルの表現力を決定します。
</Callout>

---

## CNNの学習プロセス

### 順伝播（Forward Propagation）

入力画像がネットワークの各層を順番に通過し、最終的な予測結果を得るプロセスです。

1. 画像をネットワークに入力
2. 畳み込み層で特徴を抽出
3. プーリング層で空間サイズを縮小
4. 全結合層で特徴を統合
5. 出力層で予測確率を生成

### 逆伝播（Backpropagation）

予測と正解の差（損失）を基に、ネットワークの重みを更新するプロセスです。

1. 損失関数で予測と正解の誤差を計算
2. 連鎖律（Chain Rule）を用いて誤差を出力層から入力層へ逆方向に伝播
3. 各層のパラメータの勾配を計算
4. 最適化アルゴリズム（SGD、Adam等）で重みを更新
5. このサイクルを多数回（エポック）繰り返す

### 損失関数

タスクに応じた損失関数を選択します。

- **交差エントロピー損失** — 分類タスクの標準。マルチクラスにはCategorical Cross-Entropy、二値分類にはBinary Cross-Entropyを使用
- **Focal Loss** — クラス不均衡が大きい場合（正常画像が大多数で異常が少数）に有効。誤分類の難しいサンプルに重み付けする
- **Dice Loss** — セグメンテーションタスクで頻用。領域のオーバーラップを直接最適化する

<Callout type="insight" title="医療画像AIと損失関数の選択">
医療画像データは「正常」が大多数を占めるクラス不均衡が典型的です。単純な交差エントロピーでは少数クラス（異常）の学習が不十分になりがちです。Focal Lossやクラス重み付けの導入を検討しましょう。
</Callout>

---

## 医療画像でのCNNの活用

### 画像分類

画像全体に対して1つのラベル（正常/異常、疾患名など）を付与するタスクです。

**例：胸部X線の異常検出**
- 入力：胸部X線画像（512×512）
- 畳み込み層群で肺野のテクスチャ、陰影パターン、心臓シルエットなどの特徴を抽出
- 出力：各疾患（肺炎、気胸、心拡大など）の確率

### 物体検出

画像内の病変の位置をバウンディングボックスで特定するタスクです。

**例：肺結節の検出**
- 入力：胸部CT画像
- FPNやYOLOなどの検出モデルで結節候補を検出
- 出力：結節の位置座標とサイズ、悪性確率

### セグメンテーション

画像の各ピクセルにラベルを付与し、臓器や病変の輪郭を正確に描出するタスクです。

**例：脳腫瘍のセグメンテーション**
- 入力：脳MRI画像（複数シーケンス）
- U-Netなどのエンコーダ-デコーダ構造で領域を抽出
- 出力：腫瘍領域のピクセルマスク

---

## CNNの限界と改善アプローチ

### 主要な限界

- **大量のラベル付きデータが必要** — 医療画像では専門家によるアノテーションコストが高い
- **計算リソース** — 深いモデルの学習にはGPUと大量のメモリが必要
- **説明可能性の不足** — 判断根拠がブラックボックスであり、臨床での信頼獲得に課題
- **ドメインシフト** — 訓練データと異なる施設・装置のデータでは性能が低下しやすい

### 改善アプローチ

**転移学習:**
ImageNetなどの大規模データセットで事前学習したモデルを出発点とし、医療画像データでFine-tuningする手法。少量のデータでも高い性能が期待できます（次のレッスンで詳述）。

**データ拡張:**
幾何変換や輝度変換で訓練データを擬似的に増やし、過学習を抑制します。

**アンサンブル学習:**
複数のモデルの予測を統合することで、個々のモデルの弱点を補い合い、精度と頑健性を向上させます。

**説明可能性の向上:**
Grad-CAMやAttention Mapによる重要領域の可視化で、モデルの判断根拠を視覚的に提示できます。

<Callout type="warning" title="「精度が高い＝臨床で使える」ではない">
テストデータでAUC 0.95を達成しても、説明可能性がなく施設間でドメインシフトが生じるモデルは臨床実装のハードルが高くなります。精度だけでなく、説明可能性・頑健性・ワークフロー統合を含めた総合的な評価が必要です。
</Callout>

---

## まとめ

- CNNは畳み込み層・プーリング層・全結合層から構成される画像認識の中核技術
- 局所的な特徴抽出と階層的な学習が医療画像解析で威力を発揮する
- 分類・検出・セグメンテーションの3つのタスクで広く活用されている
- 転移学習やアンサンブル、説明可能性の向上によって限界を克服するアプローチが進んでいる

次のレッスンでは、限られた医療画像データで高性能なモデルを構築するための転移学習について詳しく学びます。

---

<Quiz courseId="medical-imaging-ai-basics" lessonSlug="cnn-fundamentals" questions={[
  {
    question: "CNNの畳み込み層で使用されるフィルタ（カーネル）の役割として正しいものはどれですか？",
    options: [
      "画像のサイズを縮小する",
      "特定のパターン（エッジ、テクスチャなど）を検出して特徴マップを生成する",
      "最終的な分類結果を出力する",
      "学習データをランダムに並び替える"
    ],
    correctIndex: 1,
    explanation: "畳み込み層のフィルタは画像上を走査し、エッジやテクスチャなどの特定パターンに対する応答を特徴マップとして出力します。各フィルタは異なるパターンを学習します。"
  },
  {
    question: "医療画像のクラス不均衡問題（正常画像が大多数）に対処するための損失関数として適切なものはどれですか？",
    options: [
      "平均二乗誤差（MSE）",
      "Focal Loss",
      "Dice Loss",
      "L1正則化"
    ],
    correctIndex: 1,
    explanation: "Focal Lossは、クラス不均衡がある場合に分類の難しいサンプル（少数クラス）により大きな重みを付けることで、少数クラスの学習を促進します。医療画像では正常画像が大多数を占めるため、Focal Lossの活用が有効です。"
  },
  {
    question: "CNNで画像セグメンテーション（各ピクセルへのラベル付与）を行う際に代表的なアーキテクチャはどれですか？",
    options: [
      "VGG-16",
      "YOLO",
      "U-Net",
      "Random Forest"
    ],
    correctIndex: 2,
    explanation: "U-Netはエンコーダ-デコーダ構造とスキップ接続を持つセグメンテーション専用アーキテクチャです。医療画像セグメンテーションで最も広く使われており、脳腫瘍や臓器の輪郭抽出などで標準的に採用されています。"
  }
]} />

<ActionItem>
Grad-CAM（Gradient-weighted Class Activation Mapping）の可視化を試してみましょう。PyTorchまたはTensorFlowで事前学習済みのResNet50を使い、任意の画像に対してGrad-CAMのヒートマップを生成してください。モデルが画像のどの領域に注目しているかを視覚的に確認し、医療画像AIにおける説明可能性の重要性を体感しましょう。
</ActionItem>
