---
title: "バイアスの検出方法"
description: "公平性指標（等化オッズ・人口統計学的パリティ等）の数学的定義、サブグループ分析、不可能定理を実例で学びます"
order: 2
estimatedMinutes: 24
---

# バイアスの検出方法

## はじめに — 「全体の精度95%」が隠していたもの

ある放射線科AIが、胸部X線画像からの肺疾患検出で全体精度95%を達成しました。しかし、研究者がデータを**性別・人種別に分解**して分析したところ、黒人男性のサブグループでは精度が**82%**に低下していることが判明。

全体の平均は問題なく見えても、特定のグループに深刻な不利益が隠れている — バイアス検出が必要な理由はここにあります。

---

## データの監査 — 最初の防衛線

### 学習データの構成分析

バイアス検出の第一歩は、学習データの構成を分析することです。

- **人口統計学的バランス**: 人種、性別、年齢層の分布は母集団を反映しているか
- **疾患の分布**: 疾患の種類や重症度は偏っていないか
- **データ収集の方法**: 特定の施設・地域に偏っていないか
- **欠損データのパターン**: 特定のグループでデータの欠損が多くないか

<Callout type="insight" title="データシートの重要性">

Gebru et al.（2021）が提唱した「**Datasheets for Datasets**」は、データセットの「成分表示」のようなものです。収集方法、構成、前処理、想定される用途、既知の限界を文書化します。バイアスのある学習データの使用を防ぐための標準的なプラクティスとして広まりつつあります。

</Callout>

<ResourceCard
  type="paper"
  title="Datasheets for Datasets"
  url="https://dl.acm.org/doi/10.1145/3458723"
  authors="Gebru T, Morgenstern J, Vecchione B et al."
  source="Communications of the ACM"
  year={2021}
  description="データセットの透明な文書化のための標準フォーマット。データの出所、構成、バイアスリスクを体系的に記録"
/>

---

## サブグループ分析 — バイアスを見つける核心手法

AIの性能を、属性ごとのサブグループに分けて評価します。

| 属性 | サブグループ例 | 評価指標 |
|:---|:---|:---|
| 性別 | 男性 / 女性 | 感度、特異度、AUC |
| 年齢 | 18-40 / 41-65 / 66+ | 感度、特異度、AUC |
| 人種・民族 | 白人 / 黒人 / ヒスパニック / アジア系 | 感度、特異度、AUC |
| 疾患重症度 | 軽症 / 中等症 / 重症 | 感度、特異度 |

<CaseStudy title="CheXpertデータセットでの性別・人種別性能分析" year={2020} jurisdiction="米国" tags={["サブグループ分析", "胸部X線", "画像診断"]}>

**背景**: StanfordのCheXpertは約22万枚の胸部X線画像を含む大規模データセットで、多くの胸部X線AIのベンチマークに使用されています。

**発見**: CheXpertで学習したモデルの性能をサブグループ別に分析したところ:
- 特定の人種・性別の組み合わせ（黒人女性など）で**AUCが最大0.10低下**
- 年齢層による性能差も顕著（高齢者で精度低下の傾向）
- 交差属性（intersectional attributes）での分析が重要

**教訓**: 単一属性（性別のみ、人種のみ）での分析では見逃される**交差バイアス**がある。性別×人種など複数属性の組み合わせでの分析が不可欠。

</CaseStudy>

---

## 公平性指標 — 「何をもって公平とするか」

### 人口統計学的パリティ（Demographic Parity）

すべてのグループで**陽性と判定される割合**が等しいこと。

**医療での問題点**: 疾患の有病率がグループ間で異なる場合、同じ陽性率を目指すことは**臨床的に不適切**。

### 等化オッズ（Equalized Odds）

すべてのグループで**真陽性率（感度）と偽陽性率**が等しいこと。

**医療での利点**: 診断の「見逃し」と「誤報」の両方がグループ間で均等になり、臨床的に最も意味のある指標。

### 予測値パリティ（Predictive Parity）

すべてのグループで**陽性的中率（PPV）**が等しいこと。AIが「要精査」と判定した患者のうち、実際に疾患がある割合がどのグループでも同じ。

### 個別公平性（Individual Fairness）

類似した個人に対して**類似した予測**を行うこと。検査結果がほぼ同じ2人の患者に対して、人種が異なるだけで大きく異なるリスクスコアを付けない。

---

## 公平性の不可能定理

<Callout type="comparison" title="すべてを同時に満たすことはできない">

Chouldechova（2017）とKleinberg et al.（2017）は、**人口統計学的パリティ、等化オッズ、予測値パリティを全て同時に満たすことは数学的に不可能**な場合があることを証明しました（基準率がグループ間で異なる場合）。

→ 重要なのは、**どの公平性の定義を優先するかを意識的に選択**し、その理由を透明に説明すること。医療では通常、**等化オッズ**（見逃し率と誤報率の均等）が臨床的に最も重要。

</Callout>

<ResourceCard
  type="paper"
  title="Fair prediction with disparate impact: A study of bias in recidivism prediction instruments"
  url="https://arxiv.org/abs/1703.00056"
  authors="Chouldechova A"
  source="Big Data"
  year={2017}
  description="公平性指標間の数学的トレードオフ（不可能定理）を証明した重要論文"
/>

---

## バイアス検出のツールキット

<ResourceCard
  type="website"
  title="AI Fairness 360 (AIF360)"
  url="https://aif360.res.ibm.com/"
  source="IBM Research"
  description="70以上の公平性指標と10以上のバイアス軽減アルゴリズムを提供するオープンソースツールキット"
/>

<ResourceCard
  type="website"
  title="Fairlearn"
  url="https://fairlearn.org/"
  source="Microsoft"
  description="scikit-learn互換の公平性評価・バイアス軽減Pythonライブラリ。ダッシュボード付き"
/>

<Callout type="question" title="考えてみよう">

あなたの施設で使用している診断AIが以下の性能を示した場合、どの公平性指標が問題を最もよく捉えますか？

- 男性の感度: 95% / 女性の感度: 87%
- 男性のPPV: 86% / 女性のPPV: 90%

等化オッズの観点では感度の8ポイント差が問題。予測値パリティの観点ではPPVの差は小さい。どちらを優先するかは、「見逃しのリスク」と「不必要な追加検査のコスト」のどちらがより重大かによります。

</Callout>

---

## まとめ

バイアス検出は「全体の精度」だけでなく、**サブグループ別の性能分析**と**公平性指標の計算**を組み合わせて行います。公平性の不可能定理が示すように、すべての指標を同時に満たすことは不可能な場合があるため、「何をもって公平とするか」を意識的に定義し、透明に説明することが重要です。

次のレッスンでは、検出されたバイアスをどのように**軽減**するかを学びます。

<Quiz
  courseId="ai-bias-fairness"
  lessonSlug="02-detecting-bias"
  questions={[
    {
      question: "等化オッズ（Equalized Odds）が求める条件はどれか？",
      options: ["すべてのグループで陽性判定の割合が等しいこと", "すべてのグループで真陽性率（感度）と偽陽性率が等しいこと", "すべてのグループで陽性的中率が等しいこと", "類似した個人に類似した予測を行うこと"],
      correctIndex: 1,
      explanation: "等化オッズは、すべてのグループで感度（真陽性率）と偽陽性率が等しいことを求めます。診断の「見逃し率」と「誤報率」の両方がグループ間で均等になるため、医療では最も臨床的に意味のある公平性指標とされています。"
    },
    {
      question: "公平性の不可能定理が示すことはどれか？",
      options: ["AIは本質的に公平になれない", "基準率がグループ間で異なる場合、主要な公平性指標を全て同時に満たすことが数学的に不可能な場合がある", "バイアスは検出できない", "公平性指標は実用的ではない"],
      correctIndex: 1,
      explanation: "Chouldechova（2017）とKleinberg et al.（2017）は、基準率がグループ間で異なる場合に、主要な公平性指標を全て同時に満たすことが不可能であることを証明しました。重要なのは、どの指標を優先するかを意識的に選択することです。"
    },
    {
      question: "サブグループ分析で交差属性の分析が重要な理由はどれか？",
      options: ["計算コストを削減するため", "法的に義務付けられているため", "単一属性のみの分析では見逃される交差バイアスが存在するため", "データ量を増やすため"],
      correctIndex: 2,
      explanation: "性別のみ、人種のみの単一属性分析では見つからないバイアスが、「黒人女性」など複数属性の組み合わせで初めて現れることがあります。CheXpertの研究でも、交差属性での性能低下が報告されています。"
    }
  ]}
/>

<ActionItem>
自施設のAIシステムの予測結果を、性別・年齢層ごとにサブグループ分析してみましょう。特に交差属性（例: 高齢女性、若年男性）での性能差がないか確認することが、バイアス検出の実践的な第一歩です。
</ActionItem>
