---
title: "アンサンブル学習"
description: "複数のモデルを組み合わせて予測精度を向上させるアンサンブル学習の手法（バギング、ブースティング、スタッキング）を学びます"
order: 7
estimatedMinutes: 16
---

## このレッスンで学ぶこと

このレッスンを完了すると、アンサンブル学習の基本概念、バギング・ブースティング・スタッキングの違い、代表的なアルゴリズム（ランダムフォレスト、XGBoost等）、そして医療データへの活用を理解できるようになります。

---

## セクション1: アンサンブル学習とは

### 基本概念

アンサンブル学習は、複数のモデル（弱学習器）の予測を組み合わせることで、単一のモデルよりも高い性能を達成する手法です。

<Callout type="insight" title="「三人寄れば文殊の知恵」">
医療の世界では、複数の専門医が議論して治療方針を決定するカンファレンスが行われます。アンサンブル学習はこれと同じ発想です。個々のモデルが異なる視点でデータを分析し、その結果を統合することで、一人（一つのモデル）では気づけなかったパターンも捉えられるようになります。
</Callout>

アンサンブル学習の利点：
- **精度向上**：個々のモデルの弱点を互いに補い合う
- **安定性**：予測のばらつき（バリアンス）を低減する
- **過学習の抑制**：複数モデルの平均化により、特定データへの過剰適合を防ぐ

---

## セクション2: バギング（Bagging）

### バギングの仕組み

バギング（Bootstrap Aggregating）は、訓練データからランダムにサンプルを復元抽出して複数のモデルを学習し、その予測を統合する手法です。

手順：
1. 元の訓練データからランダムに（重複を許して）サンプルを抽出
2. 各サンプルで独立にモデルを学習する
3. 全モデルの予測を統合する（分類：多数決、回帰：平均）

### ランダムフォレスト

ランダムフォレストは、バギングの代表的なアルゴリズムで、複数の決定木を組み合わせたものです。

ランダムフォレストの特徴：
- **高い予測精度**：単一の決定木より大幅に精度が向上
- **過学習に強い**：多数の木の平均化により過学習を抑制
- **特徴量の重要度**：各特徴量がどれだけ予測に寄与しているかを評価可能
- **並列計算可能**：各木の学習は独立しているため、並列処理が可能

<Callout type="insight" title="医療研究でのランダムフォレストの人気">
ランダムフォレストは、臨床研究で最もよく使われる機械学習アルゴリズムの一つです。その理由は、高い精度に加えて特徴量の重要度を算出できるため、「どの検査値が予測に重要か」という臨床的に意味のある知見が得られることにあります。
</Callout>

---

## セクション3: ブースティング（Boosting）

### ブースティングの仕組み

ブースティングは、弱いモデルを順番に学習させ、前のモデルが間違えたデータに重点を置いて次のモデルを学習する手法です。

バギングとの違い：
- **バギング**：各モデルを独立・並列に学習
- **ブースティング**：各モデルを逐次的に学習し、前のモデルの誤りを補正

### 代表的なアルゴリズム

**AdaBoost（Adaptive Boosting）：**
誤分類されたデータに大きな重みを付与し、次の学習器がそれらを正しく分類するよう学習する。

**勾配ブースティング（Gradient Boosting）：**
前のモデルの予測誤差（残差）を次のモデルが学習する。誤差を段階的に減らしていく。

**XGBoost（eXtreme Gradient Boosting）：**
勾配ブースティングを高速化・正則化したアルゴリズム。データサイエンスコンペティションで多くの優勝を収めている。

**LightGBM：**
大規模データに特化した高速な勾配ブースティング。メモリ効率が良い。

<Callout type="comparison" title="ランダムフォレスト vs XGBoost">
ランダムフォレストは過学習しにくく安定しており、ハイパーパラメータの調整が比較的容易です。XGBoostはより高い精度を達成できる反面、ハイパーパラメータの数が多く調整に手間がかかります。初手としてランダムフォレストで性能のベースラインを確認し、さらなる精度向上が必要な場合にXGBoostを試す、という戦略が実務的です。
</Callout>

---

## セクション4: スタッキング（Stacking）

### スタッキングの仕組み

スタッキングは、異なる種類のモデルの予測結果を、別のモデル（メタ学習器）の入力として使い、最終予測を行う手法です。

手順：
1. 複数の異なるモデル（基底学習器）を訓練する（例：ロジスティック回帰、ランダムフォレスト、SVM）
2. 各基底学習器の予測結果を新しい特徴量として使う
3. メタ学習器がこれらの予測を統合して最終予測を出す

### スタッキングの利点と注意点

利点：
- 異なる特性のモデルの長所を組み合わせられる
- 各モデルが得意とするデータパターンを相補的に活用

注意点：
- 過学習しやすいため、交差検証ベースでの構築が必須
- 計算コストが高い
- モデル全体の解釈が困難

---

## 重要な洞察：アンサンブル学習の実践

<Callout type="warning" title="アンサンブルの落とし穴">
アンサンブル学習は万能ではありません。個々のモデルが同じ方向に偏った誤りをしている場合（例：訓練データのバイアス）、アンサンブルしてもバイアスは解消されません。また、モデルが複雑になるほど、結果の説明が難しくなるという「解釈可能性と精度のトレードオフ」が顕著になります。
</Callout>

医療での活用ポイント：
- **予測精度が最優先の場面**：画像診断の二次スクリーニングなど
- **特徴量の重要度を知りたい場面**：ランダムフォレストの特徴量重要度を活用
- **説明可能性が必要な場面**：アンサンブルの結果をSHAP値などで解釈可能にする

---

## まとめ

このレッスンでは、アンサンブル学習の主要手法を学びました。

重要なポイント：

1. **バギング**：複数のモデルを独立に学習し統合。ランダムフォレストが代表例
2. **ブースティング**：前のモデルの誤りを補正しながら逐次的に学習。XGBoostが代表例
3. **スタッキング**：異なるモデルの予測を統合。高精度だが複雑
4. **実践では**：まずランダムフォレストでベースラインを作り、必要に応じてブースティングやスタッキングを試す

<ActionItem>
以下のシナリオで最適なアンサンブル手法を選んでみましょう：(1) 胸部X線画像の異常検出（大量データ、高精度重視）、(2) 30変数の患者データから再入院リスクを予測（特徴量の重要度も知りたい）、(3) 3つの既存予測モデルの結果を統合して最終予測を出したい。それぞれの選択理由も考えてみてください。
</ActionItem>

<Quiz courseId="machine-learning-fundamentals" lessonSlug="ensemble-methods" questions={[
  {
    question: "バギングとブースティングの最も大きな違いは何ですか？",
    options: [
      "使用するモデルの種類が異なる",
      "バギングは並列に学習し、ブースティングは逐次的に学習する",
      "バギングは分類にのみ使え、ブースティングは回帰にのみ使える",
      "バギングの方が常に精度が高い"
    ],
    correctIndex: 1,
    explanation: "バギングは各モデルを独立・並列に学習させるのに対し、ブースティングは前のモデルの誤りに焦点を当てて次のモデルを逐次的に学習させます。"
  },
  {
    question: "ランダムフォレストが臨床研究で人気がある理由として最も適切なものはどれですか？",
    options: [
      "実装が最も簡単だから",
      "計算速度が最も速いから",
      "高い精度に加えて特徴量の重要度を算出できるから",
      "他のモデルより必ず精度が高いから"
    ],
    correctIndex: 2,
    explanation: "ランダムフォレストは高い予測精度を持つだけでなく、各特徴量の重要度を算出できるため、「どの検査値が重要か」という臨床的に意味のある知見が得られます。"
  },
  {
    question: "アンサンブル学習の共通の課題として正しいものはどれですか？",
    options: [
      "常に単一モデルより精度が低い",
      "カテゴリデータを扱えない",
      "モデルの解釈可能性が低下しやすい",
      "訓練データが少ない場合にしか使えない"
    ],
    correctIndex: 2,
    explanation: "アンサンブル学習は複数のモデルを組み合わせるため、モデル全体としての判断根拠が複雑になり、解釈可能性が低下しやすいという課題があります。医療では、SHAP値などの説明手法との併用が推奨されます。"
  }
]} />
