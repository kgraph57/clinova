---
title: "大規模言語モデル（LLM）の基礎と動作原理"
description: "LLMとは何か、パラメータ数と能力の関係、事前学習とファインチューニングの違いを学びます"
order: 2
estimatedMinutes: 18
---

# 大規模言語モデル（LLM）の基礎

## このレッスンで学ぶこと

このレッスンを完了すると、大規模言語モデル（LLM）の基本的な仕組みを理解し、パラメータ数と能力の関係、事前学習とファインチューニングの違いを把握できるようになります。

---

## セクション1: LLMとは何か

### 大規模言語モデルの定義

大規模言語モデル（Large Language Model, LLM）は、大量のテキストデータから学習した、テキストを理解し生成するAIモデルです。

特徴：

大規模言語モデルは、まず数十億から数兆という膨大なパラメータを持つという大規模性が特徴です。さらに、テキストの意味を理解する能力を持ち、これはパターン認識に基づいています。そして、新しいテキストを生成する能力も備えています。これらの特徴が組み合わさることで、LLMは強力な言語処理能力を発揮します。

### パラメータとは

パラメータは、AIモデルが学習する「重み」です。パラメータ数が多いほど、モデルはより複雑なパターンを学習できます。

パラメータ数の例：

主要なLLMのパラメータ数を見てみると、GPT-3.5は約1,750億パラメータを持ち、GPT-4は約1兆パラメータ（推定）とさらに大規模です。Claude 3は約1,000億パラメータ（推定）となっています。これらの数値は、LLMがどれほど大規模なモデルであるかを示しています。

重要な理解：
パラメータ数が多いほど性能が高いとは限りません。重要なのは、パラメータの質と、学習データの質です。

---

## セクション2: 事前学習とファインチューニング

### 事前学習（Pre-training）

事前学習は、大量の一般的なテキストデータから学習することです。これにより、AIは言語の基本的なパターンを学習します。

学習データ：

事前学習では、書籍、論文、ウェブページなど様々なテキストデータが使用され、その量は数十億から数兆のトークンに及びます。この膨大なデータから、AIは文法、構文、意味のパターンを学習し、一般的な知識を獲得し、さらに推論のパターンも身につけます。この包括的な学習プロセスが、LLMの基礎能力を形成します。

### ファインチューニング（Fine-tuning）

ファインチューニングは、特定のタスクに特化したデータで、事前学習済みモデルをさらに学習することです。

医療現場での例：

医療現場では、医学文献でファインチューニングを行うことで医療専門のAIを作成できます。また、診断書のデータでファインチューニングを行えば、診断書作成に特化したAIを開発できます。このように、ファインチューニングは特定の用途にAIを特化させる重要な手法です。

重要な違い：

事前学習では一般的な言語能力を獲得しますが、ファインチューニングでは特定のタスクに特化させることができます。この違いを理解することで、AIを効果的に活用できるようになります。

---

## セクション3: パラメータ数と能力の関係

### スケーリング則

パラメータ数が増えると、AIの能力も向上します。これを「スケーリング則」と呼びます。

能力の向上：

パラメータ数が増えることで、LLMの能力は様々な面で向上します。言語理解の面では、より複雑な文脈を理解できるようになります。推論能力においては、より複雑な推論が可能になります。また、より多くの専門知識を保持できるようになります。これらの向上が、LLMの実用性を高めています。

### 限界も存在する

しかし、パラメータ数を増やし続けても、無限に能力が向上するわけではありません。ある時点で、限界に達します。

重要な理解：
パラメータ数だけでなく、学習データの質、アーキテクチャの設計、学習方法など、様々な要素が性能に影響します。

---

## 重要な洞察：LLMの能力と限界

LLMは、大量のテキストデータから学習することで、驚くべき能力を獲得しました。しかし、その能力には限界もあります。

LLMが得意なこと：

LLMは一般的な知識の提供に優れており、テキストの生成と要約も得意としています。また、パターンに基づいた推論も行えます。これらの能力により、LLMは様々な場面で活用されています。

LLMが苦手なこと：

一方で、LLMには限界もあります。最新の情報、つまり学習データに含まれていない情報には対応できません。また、正確な事実確認は苦手であり、専門的な判断、特に医療現場での判断には注意が必要です。これらの限界を理解した上で活用することが重要です。

---

## まとめ：LLMの基礎を理解する

このレッスンでは、大規模言語モデル（LLM）の基礎を学びました。

重要なポイント：

このレッスンで学んだ重要なポイントを振り返ると、まずLLMは大量のテキストデータから学習した、テキストを理解し生成するAIであるという定義があります。パラメータはAIモデルが学習する「重み」であり、数が多いほど複雑なパターンを学習可能になります。事前学習とファインチューニングの違いは、一般的な能力を獲得するか、特定タスクに特化するかの違いです。そして、LLMは強力ですが、限界も理解する必要があるという点が重要です。

### 次のステップ

次のレッスンでは、Transformerアーキテクチャについて学びます。LLMの核心技術であるTransformerの仕組みを理解します。

---

<Quiz
  courseId="generative-ai-basics"
  lessonSlug="02-llm-fundamentals"
  questions={[
    {
      question: "大規模言語モデル（LLM）の「パラメータ」とは何ですか？",
      options: ["ユーザーが入力する設定値", "AIモデルが学習する重み", "コンテキストウィンドウのサイズ", "学習データの件数"],
      correctIndex: 1,
      explanation: "パラメータはAIモデルが学習する「重み」です。パラメータ数が多いほど、モデルはより複雑なパターンを学習できますが、パラメータ数だけで性能が決まるわけではありません。"
    },
    {
      question: "事前学習とファインチューニングの違いとして正しいものはどれですか？",
      options: ["事前学習は無料で、ファインチューニングは有料である", "事前学習は一般的な言語能力を獲得し、ファインチューニングは特定タスクに特化させる", "事前学習は小規模データ、ファインチューニングは大規模データを使う", "事前学習はテキスト、ファインチューニングは画像を対象とする"],
      correctIndex: 1,
      explanation: "事前学習は大量の一般的なテキストデータから言語の基本パターンを学習する段階で、ファインチューニングは事前学習済みモデルを特定のタスク（例：医学文献の理解、診断書作成）に特化させる追加学習です。"
    },
    {
      question: "LLMが苦手とすることとして最も適切なものはどれですか？",
      options: ["テキストの生成と要約", "一般的な知識の提供", "パターンに基づいた推論", "最新の情報や正確な事実確認"],
      correctIndex: 3,
      explanation: "LLMは学習データに含まれていない最新の情報には対応できず、正確な事実確認も苦手です。医療現場では、AIが生成した情報を必ず専門家が確認することが重要です。"
    }
  ]}
/>

<ActionItem>
明日、自分が普段使っている生成AIツール（ChatGPT、Claudeなど）に、自分の専門分野に関する質問をしてみましょう。回答の正確性を確認し、「事前学習で獲得した一般知識」と「専門分野で求められる精度」のギャップを体感してください。
</ActionItem>