---
title: "最新の法改正と動向"
description: "EU AI Act、日本のAI事業者ガイドライン、FDA AI/ML規制から、医療AIの法的未来を展望します"
order: 7
estimatedMinutes: 18
---

# 現在の法律と規制の動向

## はじめに — EU AI Act発効、世界初の包括的AI規制

2024年8月1日、EU AI Act（欧州AI規制法）が発効しました。**世界初の包括的AI規制法**であり、AIシステムをリスクレベルに応じて分類し、高リスクAIには厳格な要件を課します。

医療AI（AI搭載の医療機器・体外診断用医薬品）は**ハイリスクAI**に分類され、2027年8月から完全な遵守義務が適用されます。この法律は、EU域内で製品を販売する世界中の開発者に影響を与えます。

<CaseStudy title="EU AI Act — 医療AIはハイリスク分類" year={2024} jurisdiction="EU" tags={["AI規制", "ハイリスク", "EU AI Act"]}>

**法的根拠**: EU AI Act第6条（ハイリスクAIシステムの分類規則）。Annex IIに記載された規制（医療機器規則 MDR、体外診断用医薬品規則 IVDR）の対象となるAIシステムは、第三者適合性評価が必要な場合にハイリスクに分類。

**対象**: MDRのクラスIIa、IIb、IIIおよびIVDRのクラスB、C、Dの医療機器に搭載されたAIは原則としてハイリスク。日本のPMDA承認品がEUでも販売される場合は対応が必要。

**ハイリスクAIに課される要件**:
- **リスク管理システム**の構築と運用
- **データガバナンス**: 学習データの品質・代表性の確保
- **技術文書**: 設計・開発・テストの包括的な文書化
- **記録保持**: ログの自動記録による追跡可能性
- **透明性**: ユーザーへの適切な情報提供
- **人間による監視**: 人間がAIの判断を監視・介入できる仕組み

**タイムライン**: 2024年8月発効 → 2025年2月（禁止されるAI慣行の適用開始） → **2027年8月（ハイリスクAIの完全遵守義務開始）**。

</CaseStudy>

<ResourceCard
  type="law"
  title="EU AI Act — Article 6: Classification Rules for High-Risk AI Systems"
  url="https://artificialintelligenceact.eu/article/6/"
  source="European Union"
  year={2024}
  description="EU AI Actの条文。ハイリスクAI分類の基準を定める第6条の全文"
/>

---

## 日本の規制動向

### AI事業者ガイドライン

<CaseStudy title="AI事業者ガイドライン — 日本のソフトロー・アプローチ" year={2024} jurisdiction="日本" tags={["ガイドライン", "ソフトロー", "AI事業者"]}>

**背景**: EUが包括的なAI規制法（ハードロー）を採用したのに対し、日本は**ソフトロー・アプローチ**（法的拘束力のないガイドライン）を選択。

**AI事業者ガイドライン第1.0版**（2024年4月19日公表）: 経済産業省・総務省が共同で策定。AI開発者・提供者・利用者それぞれの責務を定める。

**v1.1版**（2025年3月28日公表）: 生成AIの急速な普及を受けた改定。高度なAIシステムに関するリスク管理を強化。

**10の基本原則**:
1. 人間中心 2. 安全性 3. 公平性 4. プライバシー保護 5. セキュリティ確保 6. 透明性 7. アカウンタビリティ 8. 教育・リテラシー 9. 公正競争確保 10. イノベーション

**医療AIへの影響**: 法的拘束力はないが、訴訟時に「業界の合理的な注意基準」として参照される可能性がある。

</CaseStudy>

<ResourceCard
  type="guideline"
  title="AI事業者ガイドライン（第1.0版）"
  url="https://www.meti.go.jp/press/2024/04/20240419004/20240419004.html"
  source="経済産業省・総務省"
  year={2024}
  description="日本のAI事業者向け統一ガイドライン。開発者・提供者・利用者の責務と10の基本原則を定める"
/>

### 次世代医療基盤法2024年改正

レッスン4で学んだ通り、2024年4月施行の改正で**仮名加工医療情報**が新設され、時系列データの有用性を保持したまま医療ビッグデータを活用できるようになりました。二段階認定制度により安全性を担保しつつ、PMDA申請資料としての利用も可能に。

---

## 国際的な規制の比較

### 主要国・地域の規制アプローチ

| 国・地域 | アプローチ | 特徴 | 医療AIへの影響 |
|:---|:---|:---|:---|
| EU | **包括的規制（ハードロー）** | AI Act + 改正PL指令 | 最も厳格。ハイリスク分類で広範な義務 |
| 米国 | **分野別規制** | FDAが医療AI、FTCが消費者保護を担当 | 柔軟だが一貫性に欠ける |
| 日本 | **ソフトロー + 既存法** | AI事業者ガイドライン + 薬機法 | 柔軟性重視。法的拘束力は弱い |
| 中国 | **包括的規制（ハードロー）** | アルゴリズム推薦管理規定等 | 政府による強い統制 |

### GDPR第22条 — 自動化された意思決定の制限

<Callout type="insight" title="GDPR第22条 — AI診断と「説明を受ける権利」">

GDPRの第22条は、個人が**自動化された処理のみに基づく意思決定の対象とならない権利**を定めています。

**医療AIへの影響**: EU圏の患者に対してAI診断支援を使用する場合、(1) 自動化された処理のみに基づかないこと（人間の関与が必要）、(2) 処理のロジックに関する**有意義な情報**を提供すること、が求められます。

→ これは日本の現行法にはない規定ですが、EU圏の患者を扱う日本の医療機関にもGDPRが域外適用される可能性があります。

</Callout>

### FDA AI/ML規制の動向

米国FDAは、AI/ML搭載医療機器に対して独自のアプローチを取っています:

- **SaMDプレマーケットプログラム**: Software as a Medical Deviceの承認プロセス
- **Predetermined Change Control Plan (PCCP)**: 事前承認された変更計画に基づくAIの継続的改良（日本のIDATENの原型）
- **2025年までに950件以上**のAI/ML搭載医療機器を承認・認可（放射線科が最多）

---

## コース全体のまとめ

このコース「医療データの法的取り扱い」で学んだ7つのレッスンを振り返ります:

| レッスン | 核心 | キーワード |
|:---|:---|:---|
| 1. 法的基礎 | 個人情報保護法・医療法・医師法の三層構造 | DeepMind事件、要配慮個人情報、守秘義務 |
| 2. 個人情報保護法の詳細 | 安全管理措置4類型と2022年改正 | 仮名加工情報、漏洩報告義務化、罰則強化 |
| 3. 医療法と医師法 | 診療録の義務と3省2ガイドライン | 電子保存三原則、第6.0版、AI使用時の記録 |
| 4. データの匿名化 | 匿名加工情報と仮名加工情報の使い分け | Netflix再識別、次世代医療基盤法、LDI |
| 5. AI診断支援の規制 | 薬機法のSaMD分類とPMDA承認 | nodoca、EIRL、EndoBRAIN、IDATEN |
| 6. AI診断の法的責任 | 三者の責任分配と自動化バイアス | Da Vinci訴訟、EU改正PL指令、注意義務 |
| 7. 最新の動向 | EU AI Act、日本のソフトロー・アプローチ | ハイリスク分類、AI事業者ガイドライン |

**最後に**: 医療AIの法規制は急速に変化しています。EU AI Actのハイリスク分類（2027年完全適用）、日本のAI事業者ガイドラインの改定、次世代医療基盤法の進展など、最新動向の継続的なフォローが不可欠です。法律は技術の進歩に遅れがちですが、「患者の安全と権利の保護」という原則は変わりません。

<Quiz
  courseId="medical-data-legal"
  lessonSlug="07-current-laws-trends"
  questions={[
    {
      question: "EU AI Actにおいて、医療AI（MDRクラスIIa以上の医療機器搭載AI）はどのリスク分類に該当するか？",
      options: ["最小リスク（規制なし）", "限定リスク（透明性義務のみ）", "ハイリスク（広範な遵守義務）", "禁止されるAI慣行"],
      correctIndex: 2,
      explanation: "EU AI Act第6条に基づき、MDRのクラスIIa、IIb、IIIの医療機器に搭載されたAIはハイリスクに分類されます。リスク管理、データガバナンス、技術文書、透明性、人間による監視などの広範な遵守義務が課されます。"
    },
    {
      question: "日本のAI規制アプローチの特徴として最も正確なものはどれか？",
      options: ["EUと同じ包括的AI規制法を制定済み", "法的拘束力のないガイドライン（ソフトロー）と既存法の組み合わせ", "AI開発を全面的に禁止している", "規制を一切行わない自由放任主義"],
      correctIndex: 1,
      explanation: "日本はEUのようなAI規制法（ハードロー）ではなく、AI事業者ガイドライン（ソフトロー）と薬機法等の既存法の組み合わせで対応しています。柔軟性重視のアプローチですが、法的拘束力が弱い点が課題です。"
    },
    {
      question: "GDPR第22条が医療AIに求める内容として正しいものはどれか？",
      options: ["AIの使用を全面的に禁止している", "自動化された処理のみに基づく意思決定を制限し、処理ロジックの説明を求める", "AI開発にGDPR準拠データのみの使用を義務付けている", "患者データの完全匿名化のみを許可している"],
      correctIndex: 1,
      explanation: "GDPR第22条は、個人が自動化された処理のみに基づく意思決定の対象とならない権利を定めています。医療AIの文脈では、人間の関与と処理ロジックに関する有意義な情報の提供が求められます。"
    }
  ]}
/>

<ActionItem>
厚生労働省・経済産業省・個人情報保護委員会・PMDAのウェブサイトをブックマークし、以下の最新動向を月1回チェックする習慣を作りましょう: (1) AI事業者ガイドラインの改定、(2) 薬機法のSaMD関連通知、(3) 次世代医療基盤法の認定事業者の動向、(4) EU AI Actの国内への影響。チーム内での月次法規制アップデート共有の仕組みも検討してみてください。
</ActionItem>
